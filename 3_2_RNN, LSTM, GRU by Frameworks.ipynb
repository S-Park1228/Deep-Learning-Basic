{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network Using Frameworks\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "NUM_WORDS = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # 'Embedding': converts a very long one-hot vector (NUM_WORDS)\n",
    "        # into a simple feature (in this case -> feature size: 16).\n",
    "        self.emb = tf.keras.layers.Embedding(NUM_WORDS, 16)\n",
    "        # SimpleRNN: vanilla RNN\n",
    "        self.rnn = tf.keras.layers.SimpleRNN(32)\n",
    "        self.dense = tf.keras.layers.Dense(2, activation = 'softmax')       \n",
    "        \n",
    "    def call(self, x, training = None, mask = None):\n",
    "        x = self.emb(x)\n",
    "        x = self.rnn(x)\n",
    "        return self.dense(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, inputs, labels, loss_object, optimizer, train_loss, train_accuracy):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training = True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "    \n",
    "@tf.function\n",
    "def test_step(model, test_inputs, test_labels, loss_object, test_loss, test_accuracy):\n",
    "    predictions = model(test_inputs, training = False)\n",
    "    t_loss = loss_object(test_labels, predictions)\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = tf.keras.datasets.imdb\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = NUM_WORDS)\n",
    "\n",
    "# setting inputs to the same length and adding padding if necessary\n",
    "# using 'pad_sequence' in Keras\n",
    "# for inputs -> pre-padding! (zero-padding)\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                       value = 0,\n",
    "                                                       padding = 'pre',\n",
    "                                                       # Use 'post' for the opposite cases.\n",
    "                                                       maxlen = 32)\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value = 0,\n",
    "                                                       padding = 'pre',\n",
    "                                                       maxlen = 32)\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model\n",
    "model = MyModel()\n",
    "\n",
    "# Loss Function\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "# Optimization Algorithm\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Performance Metrics\n",
    "train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'test_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5456036925315857, Accuracy: 0.7020400166511536, Test Loss: 0.45511192083358765, Test_Accuracy: 0.7832000255584717\n",
      "Epoch 2, Loss: 0.3624837100505829, Accuracy: 0.8430799841880798, Test Loss: 0.48506003618240356, Test_Accuracy: 0.7707200050354004\n",
      "Epoch 3, Loss: 0.23787671327590942, Accuracy: 0.9063599705696106, Test Loss: 0.6028680801391602, Test_Accuracy: 0.7651600241661072\n",
      "Epoch 4, Loss: 0.11949918419122696, Accuracy: 0.9579600095748901, Test Loss: 0.7387099862098694, Test_Accuracy: 0.7469199895858765\n",
      "Epoch 5, Loss: 0.05055755004286766, Accuracy: 0.9841600060462952, Test Loss: 0.9949736595153809, Test_Accuracy: 0.7430400252342224\n",
      "Epoch 6, Loss: 0.02663850225508213, Accuracy: 0.9912800192832947, Test Loss: 1.195212960243225, Test_Accuracy: 0.7454400062561035\n",
      "Epoch 7, Loss: 0.013936749659478664, Accuracy: 0.9962400197982788, Test Loss: 1.3949029445648193, Test_Accuracy: 0.75\n",
      "Epoch 8, Loss: 0.018623070791363716, Accuracy: 0.9935200214385986, Test Loss: 1.4062968492507935, Test_Accuracy: 0.7327600121498108\n",
      "Epoch 9, Loss: 0.020334145054221153, Accuracy: 0.9927200078964233, Test Loss: 1.5100960731506348, Test_Accuracy: 0.7316399812698364\n",
      "Epoch 10, Loss: 0.018619054928421974, Accuracy: 0.9932399988174438, Test Loss: 1.5447992086410522, Test_Accuracy: 0.7347599864006042\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    for seqs, labels in train_ds:\n",
    "        train_step(model, seqs, labels, loss_object, optimizer,\n",
    "                  train_loss, train_accuracy)\n",
    "        \n",
    "    for test_seqs, test_labels in test_ds:\n",
    "        test_step(model, test_seqs, test_labels, loss_object,\n",
    "                 test_loss, test_accuracy)\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, ' +\n",
    "         f'Loss: {train_loss.result()}, ' +\n",
    "         f'Accuracy: {train_accuracy.result()}, ' +\n",
    "         f'Test Loss: {test_loss.result()}, ' +\n",
    "         f'Test_Accuracy: {test_accuracy.result()}')\n",
    "    \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why the test results are not good enough seems to be due to the low feature dimension (in this case 16) and the low number of RNN layers. So simple RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM (Long Short Term Memory)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.emb = tf.keras.layers.Embedding(NUM_WORDS, 16)\n",
    "        # just replacing SimpleRNN with LSTM\n",
    "        self.rnn = tf.keras.layers.LSTM(32)\n",
    "        self.dense = tf.keras.layers.Dense(2, activation = 'softmax')       \n",
    "        \n",
    "    def call(self, x, training = None, mask = None):\n",
    "        x = self.emb(x)\n",
    "        x = self.rnn(x)\n",
    "        return self.dense(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0126925278455019, Accuracy: 0.995639979839325, Test Loss: 1.6280314922332764, Test_Accuracy: 0.7476800084114075\n",
      "Epoch 2, Loss: 0.011911439709365368, Accuracy: 0.995959997177124, Test Loss: 1.6492708921432495, Test_Accuracy: 0.7163599729537964\n",
      "Epoch 3, Loss: 0.010276271030306816, Accuracy: 0.9965999722480774, Test Loss: 1.725981593132019, Test_Accuracy: 0.7457600235939026\n",
      "Epoch 4, Loss: 0.008528096601366997, Accuracy: 0.9972400069236755, Test Loss: 1.7245286703109741, Test_Accuracy: 0.7318400144577026\n",
      "Epoch 5, Loss: 0.009184456430375576, Accuracy: 0.9972000122070312, Test Loss: 1.7929840087890625, Test_Accuracy: 0.7309600114822388\n",
      "Epoch 6, Loss: 0.010907646268606186, Accuracy: 0.9964399933815002, Test Loss: 1.7789119482040405, Test_Accuracy: 0.7431600093841553\n",
      "Epoch 7, Loss: 0.007512977812439203, Accuracy: 0.9974799752235413, Test Loss: 1.876678705215454, Test_Accuracy: 0.7249600291252136\n",
      "Epoch 8, Loss: 0.007751119788736105, Accuracy: 0.9973599910736084, Test Loss: 1.8964717388153076, Test_Accuracy: 0.7052800059318542\n",
      "Epoch 9, Loss: 0.009828967973589897, Accuracy: 0.9969599843025208, Test Loss: 1.9225810766220093, Test_Accuracy: 0.7231600284576416\n",
      "Epoch 10, Loss: 0.00663590244948864, Accuracy: 0.9981200098991394, Test Loss: 1.8615691661834717, Test_Accuracy: 0.7436800003051758\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    for seqs, labels in train_ds:\n",
    "        train_step(model, seqs, labels, loss_object, optimizer,\n",
    "                  train_loss, train_accuracy)\n",
    "        \n",
    "    for test_seqs, test_labels in test_ds:\n",
    "        test_step(model, test_seqs, test_labels, loss_object,\n",
    "                 test_loss, test_accuracy)\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, ' +\n",
    "         f'Loss: {train_loss.result()}, ' +\n",
    "         f'Accuracy: {train_accuracy.result()}, ' +\n",
    "         f'Test Loss: {test_loss.result()}, ' +\n",
    "         f'Test_Accuracy: {test_accuracy.result()}')\n",
    "    \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU (Gated Recurrent Units)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.emb = tf.keras.layers.Embedding(NUM_WORDS, 16)\n",
    "        # just replacing SimpleRNN with GRU\n",
    "        self.rnn = tf.keras.layers.GRU(32)\n",
    "        self.dense = tf.keras.layers.Dense(2, activation = 'softmax')       \n",
    "        \n",
    "    def call(self, x, training = None, mask = None):\n",
    "        x = self.emb(x)\n",
    "        x = self.rnn(x)\n",
    "        return self.dense(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0028990558348596096, Accuracy: 0.9991999864578247, Test Loss: 1.9898751974105835, Test_Accuracy: 0.7301999926567078\n",
      "Epoch 2, Loss: 0.010745164006948471, Accuracy: 0.995959997177124, Test Loss: 1.9018616676330566, Test_Accuracy: 0.7278000116348267\n",
      "Epoch 3, Loss: 0.013139204122126102, Accuracy: 0.9958000183105469, Test Loss: 1.7916804552078247, Test_Accuracy: 0.7285199761390686\n",
      "Epoch 4, Loss: 0.003536507487297058, Accuracy: 0.9991599917411804, Test Loss: 1.980135202407837, Test_Accuracy: 0.7309600114822388\n",
      "Epoch 5, Loss: 0.0017628748901188374, Accuracy: 0.9994800090789795, Test Loss: 2.0729358196258545, Test_Accuracy: 0.7313200235366821\n",
      "Epoch 6, Loss: 0.002960232552140951, Accuracy: 0.9991599917411804, Test Loss: 2.0972747802734375, Test_Accuracy: 0.7120400071144104\n",
      "Epoch 7, Loss: 0.016600821167230606, Accuracy: 0.9940400123596191, Test Loss: 2.004356622695923, Test_Accuracy: 0.7276800274848938\n",
      "Epoch 8, Loss: 0.006795607507228851, Accuracy: 0.9982399940490723, Test Loss: 1.9156746864318848, Test_Accuracy: 0.7287200093269348\n",
      "Epoch 9, Loss: 0.0015013759257271886, Accuracy: 0.9996799826622009, Test Loss: 2.002877950668335, Test_Accuracy: 0.7356799840927124\n",
      "Epoch 10, Loss: 0.0010761275188997388, Accuracy: 0.9996799826622009, Test Loss: 2.0711190700531006, Test_Accuracy: 0.719760000705719\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    for seqs, labels in train_ds:\n",
    "        train_step(model, seqs, labels, loss_object, optimizer,\n",
    "                  train_loss, train_accuracy)\n",
    "        \n",
    "    for test_seqs, test_labels in test_ds:\n",
    "        test_step(model, test_seqs, test_labels, loss_object,\n",
    "                 test_loss, test_accuracy)\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}, ' +\n",
    "         f'Loss: {train_loss.result()}, ' +\n",
    "         f'Accuracy: {train_accuracy.result()}, ' +\n",
    "         f'Test Loss: {test_loss.result()}, ' +\n",
    "         f'Test_Accuracy: {test_accuracy.result()}')\n",
    "    \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
