{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00edb080",
   "metadata": {},
   "source": [
    "# Overfitting in CNN\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f51465",
   "metadata": {},
   "source": [
    "Applying **Layer Normalization** and **Regularization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63842438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72cff5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16f56890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network architecture.\n",
    "# a sort of VGGNet 16\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1_1 = tf.keras.layers.Conv2D(16, (3, 3), padding = 'same',\n",
    "                                              activation = 'relu')\n",
    "        self.conv1_2 = tf.keras.layers.Conv2D(16, (3, 3), padding = 'same',\n",
    "                                              activation = 'relu')\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D((2, 2))\n",
    "        \n",
    "        self.conv2_1 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'same',\n",
    "                                              activation = 'relu')\n",
    "        self.conv2_2 = tf.keras.layers.Conv2D(32, (3, 3), padding = 'same',\n",
    "                                              activation = 'relu')\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D((2, 2))\n",
    "        \n",
    "        self.conv3_1 = tf.keras.layers.Conv2D(64, (3, 3), padding = 'same',\n",
    "                                              activation = 'relu')\n",
    "        self.conv3_2 = tf.keras.layers.Conv2D(64, (3, 3), padding = 'same',\n",
    "                                              activation = 'relu')\n",
    "        \n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(1024, activation = 'relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "        \n",
    "    def call(self, x, training = False, mask = None):\n",
    "        x = self.conv1_1(x)\n",
    "        x = self.conv1_2(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2_1(x)\n",
    "        x = self.conv2_2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3_1(x)\n",
    "        x = self.conv3_2(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        \n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a74d47fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "cifar10 = tf.keras.datasets.cifar10 # 32 X 32 X 3 video (10 classes)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(32).prefetch(1024)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_test, y_test)).batch(32).prefetch(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25b03c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 16s 8ms/step - loss: 1.4349 - accuracy: 0.4754 - val_loss: 1.1130 - val_accuracy: 0.5980\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.9590 - accuracy: 0.6611 - val_loss: 0.9133 - val_accuracy: 0.6772\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7559 - accuracy: 0.7324 - val_loss: 0.9043 - val_accuracy: 0.6944\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.5837 - accuracy: 0.7939 - val_loss: 0.8210 - val_accuracy: 0.7308\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.4055 - accuracy: 0.8569 - val_loss: 1.0431 - val_accuracy: 0.6996\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 0.2648 - accuracy: 0.9068 - val_loss: 1.2438 - val_accuracy: 0.7092\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1764 - accuracy: 0.9392 - val_loss: 1.2650 - val_accuracy: 0.7257\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1436 - accuracy: 0.9507 - val_loss: 1.4341 - val_accuracy: 0.7227\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1232 - accuracy: 0.9587 - val_loss: 1.6559 - val_accuracy: 0.7140\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1187 - accuracy: 0.9592 - val_loss: 1.7098 - val_accuracy: 0.7206\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1024 - accuracy: 0.9669 - val_loss: 1.6835 - val_accuracy: 0.7144\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1026 - accuracy: 0.9672 - val_loss: 1.8170 - val_accuracy: 0.7050\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0948 - accuracy: 0.9688 - val_loss: 1.9995 - val_accuracy: 0.7092\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0945 - accuracy: 0.9695 - val_loss: 2.0136 - val_accuracy: 0.7091\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0872 - accuracy: 0.9717 - val_loss: 2.0808 - val_accuracy: 0.6988\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0927 - accuracy: 0.9714 - val_loss: 2.0542 - val_accuracy: 0.7020\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0848 - accuracy: 0.9731 - val_loss: 2.2019 - val_accuracy: 0.7035\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0814 - accuracy: 0.9754 - val_loss: 2.1436 - val_accuracy: 0.7077\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0834 - accuracy: 0.9750 - val_loss: 2.1335 - val_accuracy: 0.7112\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0898 - accuracy: 0.9727 - val_loss: 2.2300 - val_accuracy: 0.7140\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0768 - accuracy: 0.9776 - val_loss: 2.3114 - val_accuracy: 0.7032\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0809 - accuracy: 0.9760 - val_loss: 2.4365 - val_accuracy: 0.6993\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0832 - accuracy: 0.9754 - val_loss: 2.4183 - val_accuracy: 0.7051\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0738 - accuracy: 0.9783 - val_loss: 2.4905 - val_accuracy: 0.7084\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0797 - accuracy: 0.9769 - val_loss: 2.7660 - val_accuracy: 0.6987\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0758 - accuracy: 0.9785 - val_loss: 2.7744 - val_accuracy: 0.6874\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0777 - accuracy: 0.9781 - val_loss: 2.7464 - val_accuracy: 0.6954\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0745 - accuracy: 0.9797 - val_loss: 2.7041 - val_accuracy: 0.7071\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0786 - accuracy: 0.9782 - val_loss: 2.6773 - val_accuracy: 0.7016\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0764 - accuracy: 0.9793 - val_loss: 2.8071 - val_accuracy: 0.7023\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0758 - accuracy: 0.9789 - val_loss: 2.7649 - val_accuracy: 0.6961\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0715 - accuracy: 0.9805 - val_loss: 2.5532 - val_accuracy: 0.7069\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0756 - accuracy: 0.9793 - val_loss: 2.9588 - val_accuracy: 0.6983\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0763 - accuracy: 0.9801 - val_loss: 2.7766 - val_accuracy: 0.7033\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0835 - accuracy: 0.9789 - val_loss: 2.8771 - val_accuracy: 0.6957\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0747 - accuracy: 0.9809 - val_loss: 3.1945 - val_accuracy: 0.6876\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0713 - accuracy: 0.9810 - val_loss: 2.9686 - val_accuracy: 0.6839\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0801 - accuracy: 0.9796 - val_loss: 3.1643 - val_accuracy: 0.6925\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0636 - accuracy: 0.9843 - val_loss: 3.1858 - val_accuracy: 0.6978\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0720 - accuracy: 0.9808 - val_loss: 3.2580 - val_accuracy: 0.6991\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0791 - accuracy: 0.9802 - val_loss: 3.1317 - val_accuracy: 0.6917\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0682 - accuracy: 0.9826 - val_loss: 3.2991 - val_accuracy: 0.6944\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0735 - accuracy: 0.9815 - val_loss: 3.5250 - val_accuracy: 0.6935\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0704 - accuracy: 0.9825 - val_loss: 3.4442 - val_accuracy: 0.6992\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0793 - accuracy: 0.9809 - val_loss: 3.4825 - val_accuracy: 0.6845\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0832 - accuracy: 0.9798 - val_loss: 3.3730 - val_accuracy: 0.6978\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0705 - accuracy: 0.9823 - val_loss: 3.3378 - val_accuracy: 0.6987\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0727 - accuracy: 0.9824 - val_loss: 3.7809 - val_accuracy: 0.6864\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0808 - accuracy: 0.9813 - val_loss: 3.4897 - val_accuracy: 0.6964\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0758 - accuracy: 0.9823 - val_loss: 3.7966 - val_accuracy: 0.6859\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0787 - accuracy: 0.9822 - val_loss: 3.9277 - val_accuracy: 0.6872\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0720 - accuracy: 0.9833 - val_loss: 4.0208 - val_accuracy: 0.6920\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0766 - accuracy: 0.9830 - val_loss: 3.7006 - val_accuracy: 0.6997\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0666 - accuracy: 0.9845 - val_loss: 3.5741 - val_accuracy: 0.6984\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0766 - accuracy: 0.9829 - val_loss: 3.4422 - val_accuracy: 0.6991\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0756 - accuracy: 0.9831 - val_loss: 4.0714 - val_accuracy: 0.6893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0651 - accuracy: 0.9851 - val_loss: 4.5613 - val_accuracy: 0.6831\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0825 - accuracy: 0.9816 - val_loss: 4.1591 - val_accuracy: 0.6861\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0700 - accuracy: 0.9855 - val_loss: 4.1197 - val_accuracy: 0.7059\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0763 - accuracy: 0.9840 - val_loss: 4.0153 - val_accuracy: 0.6899\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0738 - accuracy: 0.9833 - val_loss: 4.1916 - val_accuracy: 0.6968\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0801 - accuracy: 0.9829 - val_loss: 4.3168 - val_accuracy: 0.6896\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0780 - accuracy: 0.9835 - val_loss: 3.9737 - val_accuracy: 0.6928\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0679 - accuracy: 0.9851 - val_loss: 4.0930 - val_accuracy: 0.6955\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0768 - accuracy: 0.9840 - val_loss: 4.2102 - val_accuracy: 0.6963\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0796 - accuracy: 0.9836 - val_loss: 4.7575 - val_accuracy: 0.6934\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0766 - accuracy: 0.9848 - val_loss: 4.3056 - val_accuracy: 0.6931\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0737 - accuracy: 0.9844 - val_loss: 4.6671 - val_accuracy: 0.6832\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0779 - accuracy: 0.9846 - val_loss: 4.8316 - val_accuracy: 0.6799\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0837 - accuracy: 0.9835 - val_loss: 4.6703 - val_accuracy: 0.7003\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0840 - accuracy: 0.9833 - val_loss: 4.5881 - val_accuracy: 0.6826\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0754 - accuracy: 0.9853 - val_loss: 4.6756 - val_accuracy: 0.6888\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0766 - accuracy: 0.9849 - val_loss: 4.4145 - val_accuracy: 0.7009\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0741 - accuracy: 0.9853 - val_loss: 5.2830 - val_accuracy: 0.6761\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0824 - accuracy: 0.9848 - val_loss: 4.6201 - val_accuracy: 0.6986\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0724 - accuracy: 0.9861 - val_loss: 5.2889 - val_accuracy: 0.6915\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0804 - accuracy: 0.9854 - val_loss: 4.7593 - val_accuracy: 0.6934\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0749 - accuracy: 0.9856 - val_loss: 5.1915 - val_accuracy: 0.6888\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0742 - accuracy: 0.9862 - val_loss: 4.8724 - val_accuracy: 0.6894\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0683 - accuracy: 0.9868 - val_loss: 4.8950 - val_accuracy: 0.6902\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0927 - accuracy: 0.9838 - val_loss: 4.7280 - val_accuracy: 0.6946\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0788 - accuracy: 0.9851 - val_loss: 5.0275 - val_accuracy: 0.6861\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0732 - accuracy: 0.9858 - val_loss: 5.3439 - val_accuracy: 0.6690\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0760 - accuracy: 0.9859 - val_loss: 5.3734 - val_accuracy: 0.6865\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0884 - accuracy: 0.9846 - val_loss: 5.3590 - val_accuracy: 0.6933\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0853 - accuracy: 0.9847 - val_loss: 5.5233 - val_accuracy: 0.6853\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0790 - accuracy: 0.9862 - val_loss: 5.2922 - val_accuracy: 0.6829\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0854 - accuracy: 0.9853 - val_loss: 5.6749 - val_accuracy: 0.6741\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0836 - accuracy: 0.9857 - val_loss: 5.2583 - val_accuracy: 0.6851\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0724 - accuracy: 0.9883 - val_loss: 5.5214 - val_accuracy: 0.6921\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1003 - accuracy: 0.9834 - val_loss: 6.3851 - val_accuracy: 0.6797\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0796 - accuracy: 0.9867 - val_loss: 6.2445 - val_accuracy: 0.6672\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0841 - accuracy: 0.9868 - val_loss: 6.0090 - val_accuracy: 0.6905\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0896 - accuracy: 0.9862 - val_loss: 5.9272 - val_accuracy: 0.6975\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0909 - accuracy: 0.9855 - val_loss: 5.7515 - val_accuracy: 0.6868\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0822 - accuracy: 0.9867 - val_loss: 6.1491 - val_accuracy: 0.6849\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0811 - accuracy: 0.9867 - val_loss: 6.2982 - val_accuracy: 0.6915\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0724 - accuracy: 0.9878 - val_loss: 6.1492 - val_accuracy: 0.6881\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0906 - accuracy: 0.9865 - val_loss: 6.6656 - val_accuracy: 0.6910\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.0911 - accuracy: 0.9859 - val_loss: 6.6465 - val_accuracy: 0.6976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2144be822e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "model = MyModel()\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "model.fit(train_ds, validation_data = test_ds, epochs = EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54b0c92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, the gap between the training performance\n",
    "# and the validation performace is too large. -> Overfitting!\n",
    "\n",
    "# Layer Normalization ('use_bias' = False due to Layer Normalization\n",
    "#                                         Recall 'fuse'!)\n",
    "class ConvLNReLUBlock(tf.keras.Model):\n",
    "    def __init__(self, num_filters, kernel_size):\n",
    "        super(ConvLNReLUBlock, self).__init__()\n",
    "        self.conv = tf.keras.layers.Conv2D(num_filters, kernel_size,\n",
    "                                           padding = 'same', use_bias = False)\n",
    "        self.ln = tf.keras.layers.LayerNormalization()\n",
    "        \n",
    "    def call(self, x, training = False, mask = None):\n",
    "        x = self.conv(x)\n",
    "        # Layer Normalization has to do with layer not batch.\n",
    "        # Thus, we do not have to insert 'training flag' into\n",
    "        # the self.ln().\n",
    "        x = self.ln(x)\n",
    "        \n",
    "        return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f56b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying Layer Normalization and Regularization (Kernel Regularization)\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1_1 = ConvLNReLUBlock(16, (3, 3))\n",
    "        self.conv1_2 = ConvLNReLUBlock(16, (3, 3))\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D((2, 2))\n",
    "        \n",
    "        self.conv2_1 = ConvLNReLUBlock(32, (3, 3))\n",
    "        self.conv2_2 = ConvLNReLUBlock(32, (3, 3))\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D((2, 2))\n",
    "        \n",
    "        self.conv3_1 = ConvLNReLUBlock(64, (3, 3))\n",
    "        self.conv3_2 = ConvLNReLUBlock(64, (3, 3))\n",
    "        \n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        # kernel_regularization: kernel = filter (weights)\n",
    "        # l2: L2-Regularization (In this case, lambda = 0.01.)\n",
    "        self.dense1 = tf.keras.layers.Dense(1024, activation = 'relu',\n",
    "                                            kernel_regularizer = tf.keras.regularizers.l2(0.01))\n",
    "        self.dense2 = tf.keras.layers.Dense(10, activation = 'softmax',\n",
    "                                            kernel_regularizer = tf.keras.regularizers.l2(0.01))\n",
    "        \n",
    "    def call(self, x, training = False, mask = None):\n",
    "        x = self.conv1_1(x)\n",
    "        x = self.conv1_2(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2_1(x)\n",
    "        x = self.conv2_2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3_1(x)\n",
    "        x = self.conv3_2(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        \n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ef99900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 37s 23ms/step - loss: 2.1760 - accuracy: 0.4070 - val_loss: 1.3853 - val_accuracy: 0.5374\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 1.2852 - accuracy: 0.5889 - val_loss: 1.1691 - val_accuracy: 0.6378\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 1.1085 - accuracy: 0.6525 - val_loss: 1.0425 - val_accuracy: 0.6849\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 1.0132 - accuracy: 0.6864 - val_loss: 0.9727 - val_accuracy: 0.7126\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.9460 - accuracy: 0.7117 - val_loss: 0.9531 - val_accuracy: 0.7158\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.8918 - accuracy: 0.7303 - val_loss: 0.9544 - val_accuracy: 0.7065\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.8454 - accuracy: 0.7451 - val_loss: 0.8844 - val_accuracy: 0.7335\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.8055 - accuracy: 0.7609 - val_loss: 0.8739 - val_accuracy: 0.7410\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.7752 - accuracy: 0.7704 - val_loss: 0.8397 - val_accuracy: 0.7464\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.7453 - accuracy: 0.7819 - val_loss: 0.8570 - val_accuracy: 0.7442\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.7125 - accuracy: 0.7930 - val_loss: 0.8075 - val_accuracy: 0.7645\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.6910 - accuracy: 0.7989 - val_loss: 0.8011 - val_accuracy: 0.7650\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.6702 - accuracy: 0.8092 - val_loss: 0.7511 - val_accuracy: 0.7871\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.6461 - accuracy: 0.8169 - val_loss: 0.7347 - val_accuracy: 0.7859\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.6264 - accuracy: 0.8232 - val_loss: 0.7904 - val_accuracy: 0.7673\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.6094 - accuracy: 0.8298 - val_loss: 0.7987 - val_accuracy: 0.7698\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.5969 - accuracy: 0.8333 - val_loss: 0.8144 - val_accuracy: 0.7653\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.5800 - accuracy: 0.8416 - val_loss: 0.7776 - val_accuracy: 0.7794\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.5645 - accuracy: 0.8454 - val_loss: 0.7984 - val_accuracy: 0.7766\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.5483 - accuracy: 0.8514 - val_loss: 0.7806 - val_accuracy: 0.7813\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.5311 - accuracy: 0.8583 - val_loss: 0.7384 - val_accuracy: 0.7922\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.5248 - accuracy: 0.8597 - val_loss: 0.8375 - val_accuracy: 0.7707\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.5097 - accuracy: 0.8652 - val_loss: 0.7489 - val_accuracy: 0.7945\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.4973 - accuracy: 0.8717 - val_loss: 0.7544 - val_accuracy: 0.7935\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.4879 - accuracy: 0.8737 - val_loss: 0.8228 - val_accuracy: 0.7727\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.4734 - accuracy: 0.8783 - val_loss: 0.7799 - val_accuracy: 0.7953\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.4619 - accuracy: 0.8854 - val_loss: 0.7841 - val_accuracy: 0.7873\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.4558 - accuracy: 0.8858 - val_loss: 0.7855 - val_accuracy: 0.7889\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.4421 - accuracy: 0.8911 - val_loss: 0.7947 - val_accuracy: 0.7877\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.4330 - accuracy: 0.8954 - val_loss: 0.7993 - val_accuracy: 0.7838\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.4216 - accuracy: 0.8979 - val_loss: 0.8129 - val_accuracy: 0.7867\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 0.4136 - accuracy: 0.9032 - val_loss: 0.8447 - val_accuracy: 0.7825\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.4097 - accuracy: 0.9008 - val_loss: 0.8114 - val_accuracy: 0.7926\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.3981 - accuracy: 0.9069 - val_loss: 0.8796 - val_accuracy: 0.7744\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3875 - accuracy: 0.9100 - val_loss: 0.8660 - val_accuracy: 0.7785\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.3845 - accuracy: 0.9116 - val_loss: 0.8675 - val_accuracy: 0.7797\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.3747 - accuracy: 0.9156 - val_loss: 0.9019 - val_accuracy: 0.7765\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.3654 - accuracy: 0.9198 - val_loss: 0.8809 - val_accuracy: 0.7865\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.3600 - accuracy: 0.9219 - val_loss: 0.8539 - val_accuracy: 0.7849\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 34s 21ms/step - loss: 0.3512 - accuracy: 0.9237 - val_loss: 0.9160 - val_accuracy: 0.7698\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.3452 - accuracy: 0.9262 - val_loss: 0.8849 - val_accuracy: 0.7805\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.3385 - accuracy: 0.9279 - val_loss: 0.8733 - val_accuracy: 0.7851\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.3349 - accuracy: 0.9299 - val_loss: 0.8883 - val_accuracy: 0.7830\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.3266 - accuracy: 0.9325 - val_loss: 0.9505 - val_accuracy: 0.7718\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.3213 - accuracy: 0.9344 - val_loss: 0.9039 - val_accuracy: 0.7849\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.3181 - accuracy: 0.9347 - val_loss: 0.8846 - val_accuracy: 0.7807\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.3096 - accuracy: 0.9375 - val_loss: 0.9275 - val_accuracy: 0.7811\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.3125 - accuracy: 0.9371 - val_loss: 0.9628 - val_accuracy: 0.7798\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.3023 - accuracy: 0.9408 - val_loss: 1.0455 - val_accuracy: 0.7606\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.3007 - accuracy: 0.9410 - val_loss: 0.9595 - val_accuracy: 0.7793\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.2931 - accuracy: 0.9448 - val_loss: 0.9627 - val_accuracy: 0.7774\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.2955 - accuracy: 0.9418 - val_loss: 0.9502 - val_accuracy: 0.7802\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 35s 22ms/step - loss: 0.2862 - accuracy: 0.9463 - val_loss: 0.9617 - val_accuracy: 0.7791\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.2852 - accuracy: 0.9464 - val_loss: 0.9993 - val_accuracy: 0.7683\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2840 - accuracy: 0.9467 - val_loss: 1.0200 - val_accuracy: 0.7723\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2821 - accuracy: 0.9479 - val_loss: 0.9685 - val_accuracy: 0.7806\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2757 - accuracy: 0.9503 - val_loss: 0.9904 - val_accuracy: 0.7770\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2710 - accuracy: 0.9511 - val_loss: 1.0146 - val_accuracy: 0.7688\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.2702 - accuracy: 0.9520 - val_loss: 1.0789 - val_accuracy: 0.7655\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.2630 - accuracy: 0.9540 - val_loss: 1.0397 - val_accuracy: 0.7789\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.2678 - accuracy: 0.9517 - val_loss: 1.0115 - val_accuracy: 0.7730\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.2636 - accuracy: 0.9536 - val_loss: 1.0006 - val_accuracy: 0.7723\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.2589 - accuracy: 0.9551 - val_loss: 0.9916 - val_accuracy: 0.7820\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2537 - accuracy: 0.9571 - val_loss: 1.0657 - val_accuracy: 0.7707\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2572 - accuracy: 0.9554 - val_loss: 1.0164 - val_accuracy: 0.7734\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.2518 - accuracy: 0.9573 - val_loss: 1.0347 - val_accuracy: 0.7741\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2508 - accuracy: 0.9583 - val_loss: 1.0793 - val_accuracy: 0.7675\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2487 - accuracy: 0.9571 - val_loss: 1.0331 - val_accuracy: 0.7786\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.2471 - accuracy: 0.9587 - val_loss: 1.0382 - val_accuracy: 0.7776\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.2407 - accuracy: 0.9609 - val_loss: 1.0640 - val_accuracy: 0.7670\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.2453 - accuracy: 0.9587 - val_loss: 1.0574 - val_accuracy: 0.7733\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.2390 - accuracy: 0.9613 - val_loss: 1.0768 - val_accuracy: 0.7737\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2356 - accuracy: 0.9624 - val_loss: 1.0640 - val_accuracy: 0.7735\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 35s 23ms/step - loss: 0.2413 - accuracy: 0.9597 - val_loss: 1.0168 - val_accuracy: 0.7785\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.2348 - accuracy: 0.9635 - val_loss: 1.0595 - val_accuracy: 0.7770\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.2292 - accuracy: 0.9643 - val_loss: 1.0618 - val_accuracy: 0.7685\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 33s 21ms/step - loss: 0.2304 - accuracy: 0.9644 - val_loss: 1.0539 - val_accuracy: 0.7763\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.2280 - accuracy: 0.9633 - val_loss: 1.0813 - val_accuracy: 0.7751\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.2312 - accuracy: 0.9631 - val_loss: 1.0753 - val_accuracy: 0.7730\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.2283 - accuracy: 0.9635 - val_loss: 1.0545 - val_accuracy: 0.7828\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.2242 - accuracy: 0.9652 - val_loss: 1.1022 - val_accuracy: 0.7742\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.2204 - accuracy: 0.9668 - val_loss: 1.0754 - val_accuracy: 0.7743\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.2218 - accuracy: 0.9657 - val_loss: 1.1099 - val_accuracy: 0.7671\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.2234 - accuracy: 0.9644 - val_loss: 1.0754 - val_accuracy: 0.7729\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.2197 - accuracy: 0.9658 - val_loss: 1.0760 - val_accuracy: 0.7769\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.2096 - accuracy: 0.9695 - val_loss: 1.0842 - val_accuracy: 0.7741\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.2124 - accuracy: 0.9679 - val_loss: 1.0676 - val_accuracy: 0.7748\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.2116 - accuracy: 0.9689 - val_loss: 1.0688 - val_accuracy: 0.7731\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.2148 - accuracy: 0.9681 - val_loss: 1.0774 - val_accuracy: 0.7817\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.2101 - accuracy: 0.9690 - val_loss: 1.0670 - val_accuracy: 0.7754\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.2078 - accuracy: 0.9698 - val_loss: 1.0822 - val_accuracy: 0.7829\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 32s 20ms/step - loss: 0.2123 - accuracy: 0.9672 - val_loss: 1.1243 - val_accuracy: 0.7756\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.2027 - accuracy: 0.9705 - val_loss: 1.0497 - val_accuracy: 0.7754\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.1988 - accuracy: 0.9720 - val_loss: 1.0413 - val_accuracy: 0.7760\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.2043 - accuracy: 0.9712 - val_loss: 1.0694 - val_accuracy: 0.7781\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.2003 - accuracy: 0.9714 - val_loss: 1.1061 - val_accuracy: 0.7718\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.2037 - accuracy: 0.9702 - val_loss: 1.1682 - val_accuracy: 0.7662\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.2013 - accuracy: 0.9709 - val_loss: 1.1015 - val_accuracy: 0.7715\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.2026 - accuracy: 0.9706 - val_loss: 1.1044 - val_accuracy: 0.7789\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 0.1948 - accuracy: 0.9725 - val_loss: 1.0940 - val_accuracy: 0.7814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2145aaeb9d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "model2 = MyModel()\n",
    "model2.compile(optimizer = 'adam',\n",
    "               loss = 'sparse_categorical_crossentropy',\n",
    "               metrics = ['accuracy'])\n",
    "model2.fit(train_ds, validation_data = test_ds, epochs = EPOCHS)\n",
    "\n",
    "# improved validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a131b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e880de95",
   "metadata": {},
   "source": [
    "# Underfitting\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fe79f5",
   "metadata": {},
   "source": [
    "With restricted computing resources, maximize the model's performance. <br>$\\rightarrow$ Naturally, the model is susceptible to **underfitting problems**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8049e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel_Under(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel_Under, self).__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(32, activation = 'relu')\n",
    "        # weight: 32 X 64 matrix\n",
    "        self.dense2 = tf.keras.layers.Dense(64, activation = 'relu')\n",
    "        # weight: 64 X 128 matrix\n",
    "        self.dense3 = tf.keras.layers.Dense(128, activation = 'relu')\n",
    "        # weight: 128 X 256 matrix\n",
    "        self.dense4 = tf.keras.layers.Dense(256, activation = 'relu')\n",
    "        self.dense5 = tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "        \n",
    "    def call(self, x, training = False, mask = None):\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dense4(x)\n",
    "        \n",
    "        return self.dense5(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e1ce5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist # 28 X 28 (10 classes)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(32).prefetch(2048)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_test, y_test)).batch(32).prefetch(2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df4cca0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.5125 - accuracy: 0.8124 - val_loss: 0.4469 - val_accuracy: 0.8372\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.3886 - accuracy: 0.8557 - val_loss: 0.4075 - val_accuracy: 0.8506\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3547 - accuracy: 0.8698 - val_loss: 0.3939 - val_accuracy: 0.8611\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3342 - accuracy: 0.8767 - val_loss: 0.3711 - val_accuracy: 0.8652\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3168 - accuracy: 0.8820 - val_loss: 0.3955 - val_accuracy: 0.8554\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.3056 - accuracy: 0.8857 - val_loss: 0.3485 - val_accuracy: 0.8731\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2939 - accuracy: 0.8907 - val_loss: 0.3513 - val_accuracy: 0.8743\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2839 - accuracy: 0.8933 - val_loss: 0.3692 - val_accuracy: 0.8680\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2757 - accuracy: 0.8959 - val_loss: 0.3411 - val_accuracy: 0.8811\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2674 - accuracy: 0.8984 - val_loss: 0.3564 - val_accuracy: 0.8722\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2614 - accuracy: 0.9017 - val_loss: 0.3649 - val_accuracy: 0.8736\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2545 - accuracy: 0.9037 - val_loss: 0.3490 - val_accuracy: 0.8788\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2483 - accuracy: 0.9063 - val_loss: 0.3878 - val_accuracy: 0.8674\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2416 - accuracy: 0.9068 - val_loss: 0.3451 - val_accuracy: 0.8807\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2379 - accuracy: 0.9094 - val_loss: 0.3797 - val_accuracy: 0.8761\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2311 - accuracy: 0.9108 - val_loss: 0.3587 - val_accuracy: 0.8759\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2275 - accuracy: 0.9129 - val_loss: 0.3803 - val_accuracy: 0.8809\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2223 - accuracy: 0.9145 - val_loss: 0.3656 - val_accuracy: 0.8829\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2179 - accuracy: 0.9157 - val_loss: 0.3709 - val_accuracy: 0.8804\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2138 - accuracy: 0.9182 - val_loss: 0.3594 - val_accuracy: 0.8830\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2104 - accuracy: 0.9193 - val_loss: 0.3830 - val_accuracy: 0.8851\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2081 - accuracy: 0.9201 - val_loss: 0.4000 - val_accuracy: 0.8828\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2048 - accuracy: 0.9212 - val_loss: 0.3811 - val_accuracy: 0.8862\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2015 - accuracy: 0.9225 - val_loss: 0.3816 - val_accuracy: 0.8847\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1960 - accuracy: 0.9233 - val_loss: 0.4139 - val_accuracy: 0.8800\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1930 - accuracy: 0.9254 - val_loss: 0.4086 - val_accuracy: 0.8826\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1915 - accuracy: 0.9248 - val_loss: 0.4037 - val_accuracy: 0.8818\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1874 - accuracy: 0.9275 - val_loss: 0.3925 - val_accuracy: 0.8838\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1853 - accuracy: 0.9273 - val_loss: 0.3955 - val_accuracy: 0.8843\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1806 - accuracy: 0.9300 - val_loss: 0.4229 - val_accuracy: 0.8860\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1825 - accuracy: 0.9295 - val_loss: 0.4149 - val_accuracy: 0.8852\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1772 - accuracy: 0.9309 - val_loss: 0.4437 - val_accuracy: 0.8829\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1748 - accuracy: 0.9307 - val_loss: 0.4296 - val_accuracy: 0.8854\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1738 - accuracy: 0.9319 - val_loss: 0.4569 - val_accuracy: 0.8781\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1696 - accuracy: 0.9337 - val_loss: 0.4629 - val_accuracy: 0.8764\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1701 - accuracy: 0.9337 - val_loss: 0.4417 - val_accuracy: 0.8834\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1693 - accuracy: 0.9347 - val_loss: 0.4540 - val_accuracy: 0.8849\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1664 - accuracy: 0.9349 - val_loss: 0.4705 - val_accuracy: 0.8752\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1629 - accuracy: 0.9353 - val_loss: 0.4402 - val_accuracy: 0.8845\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1595 - accuracy: 0.9379 - val_loss: 0.4500 - val_accuracy: 0.8813\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1602 - accuracy: 0.9379 - val_loss: 0.4523 - val_accuracy: 0.8850\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1526 - accuracy: 0.9401 - val_loss: 0.4678 - val_accuracy: 0.8870\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1575 - accuracy: 0.9395 - val_loss: 0.4861 - val_accuracy: 0.8872\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1552 - accuracy: 0.9394 - val_loss: 0.4862 - val_accuracy: 0.8847\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1536 - accuracy: 0.9399 - val_loss: 0.5008 - val_accuracy: 0.8812\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1496 - accuracy: 0.9414 - val_loss: 0.5071 - val_accuracy: 0.8763\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1500 - accuracy: 0.9419 - val_loss: 0.5273 - val_accuracy: 0.8869\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1476 - accuracy: 0.9419 - val_loss: 0.5519 - val_accuracy: 0.8777\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1458 - accuracy: 0.9435 - val_loss: 0.5241 - val_accuracy: 0.8812\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1488 - accuracy: 0.9421 - val_loss: 0.5821 - val_accuracy: 0.8774\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1465 - accuracy: 0.9428 - val_loss: 0.5128 - val_accuracy: 0.8810\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1408 - accuracy: 0.9451 - val_loss: 0.5696 - val_accuracy: 0.8811\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1423 - accuracy: 0.9444 - val_loss: 0.5709 - val_accuracy: 0.8772\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1395 - accuracy: 0.9457 - val_loss: 0.5563 - val_accuracy: 0.8817\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1438 - accuracy: 0.9444 - val_loss: 0.5738 - val_accuracy: 0.8826\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1357 - accuracy: 0.9469 - val_loss: 0.6311 - val_accuracy: 0.8775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1380 - accuracy: 0.9461 - val_loss: 0.5819 - val_accuracy: 0.8815\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1365 - accuracy: 0.9469 - val_loss: 0.5725 - val_accuracy: 0.8780\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1365 - accuracy: 0.9469 - val_loss: 0.5862 - val_accuracy: 0.8809\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1348 - accuracy: 0.9474 - val_loss: 0.6527 - val_accuracy: 0.8816\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1366 - accuracy: 0.9478 - val_loss: 0.6106 - val_accuracy: 0.8814\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1330 - accuracy: 0.9484 - val_loss: 0.5902 - val_accuracy: 0.8841\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1347 - accuracy: 0.9477 - val_loss: 0.5878 - val_accuracy: 0.8837\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1284 - accuracy: 0.9504 - val_loss: 0.6977 - val_accuracy: 0.8787\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1364 - accuracy: 0.9487 - val_loss: 0.6478 - val_accuracy: 0.8778\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1334 - accuracy: 0.9484 - val_loss: 0.6339 - val_accuracy: 0.8788\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1307 - accuracy: 0.9495 - val_loss: 0.6365 - val_accuracy: 0.8830\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1276 - accuracy: 0.9512 - val_loss: 0.6540 - val_accuracy: 0.8841\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1313 - accuracy: 0.9494 - val_loss: 0.7038 - val_accuracy: 0.8788\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1228 - accuracy: 0.9526 - val_loss: 0.6761 - val_accuracy: 0.8839\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1279 - accuracy: 0.9501 - val_loss: 0.6306 - val_accuracy: 0.8806\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1214 - accuracy: 0.9532 - val_loss: 0.6674 - val_accuracy: 0.8802\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1254 - accuracy: 0.9526 - val_loss: 0.6767 - val_accuracy: 0.8817\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1275 - accuracy: 0.9511 - val_loss: 0.7214 - val_accuracy: 0.8775\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1262 - accuracy: 0.9512 - val_loss: 0.6589 - val_accuracy: 0.8841\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1260 - accuracy: 0.9523 - val_loss: 0.6545 - val_accuracy: 0.8824\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1179 - accuracy: 0.9543 - val_loss: 0.7089 - val_accuracy: 0.8856\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1269 - accuracy: 0.9521 - val_loss: 0.7692 - val_accuracy: 0.8633\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1215 - accuracy: 0.9528 - val_loss: 0.8248 - val_accuracy: 0.8828\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1167 - accuracy: 0.9562 - val_loss: 0.7113 - val_accuracy: 0.8766\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1230 - accuracy: 0.9538 - val_loss: 0.6830 - val_accuracy: 0.8838\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1206 - accuracy: 0.9535 - val_loss: 0.8127 - val_accuracy: 0.8776\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1201 - accuracy: 0.9541 - val_loss: 0.7276 - val_accuracy: 0.8831\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1205 - accuracy: 0.9537 - val_loss: 0.8020 - val_accuracy: 0.8799\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1197 - accuracy: 0.9546 - val_loss: 0.6812 - val_accuracy: 0.8807\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1161 - accuracy: 0.9549 - val_loss: 0.8545 - val_accuracy: 0.8783\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1168 - accuracy: 0.9556 - val_loss: 0.8125 - val_accuracy: 0.8796\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1145 - accuracy: 0.9569 - val_loss: 0.8340 - val_accuracy: 0.8775\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1105 - accuracy: 0.9574 - val_loss: 0.8347 - val_accuracy: 0.8797\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1171 - accuracy: 0.9560 - val_loss: 0.7746 - val_accuracy: 0.8826\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1169 - accuracy: 0.9562 - val_loss: 0.7742 - val_accuracy: 0.8784\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1184 - accuracy: 0.9561 - val_loss: 0.7619 - val_accuracy: 0.8825\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1176 - accuracy: 0.9558 - val_loss: 0.7147 - val_accuracy: 0.8791\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1035 - accuracy: 0.9603 - val_loss: 0.8754 - val_accuracy: 0.8768\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1137 - accuracy: 0.9572 - val_loss: 0.8270 - val_accuracy: 0.8801\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1096 - accuracy: 0.9585 - val_loss: 0.8275 - val_accuracy: 0.8813\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1186 - accuracy: 0.9564 - val_loss: 0.7842 - val_accuracy: 0.8790\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1116 - accuracy: 0.9577 - val_loss: 0.8490 - val_accuracy: 0.8791\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1098 - accuracy: 0.9577 - val_loss: 0.7784 - val_accuracy: 0.8753\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1125 - accuracy: 0.9578 - val_loss: 0.9367 - val_accuracy: 0.8796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2147d59cbb0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "model3 = MyModel_Under()\n",
    "model3.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "model3.fit(train_ds, validation_data = test_ds, epochs = EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4421ec9",
   "metadata": {},
   "source": [
    "The modified model's performance might be worse than the original one. However, our objective is to maximize its performance given computing resources (given the model's complexity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d261db92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DenseNet\n",
    "class MyModel_Under(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel_Under, self).__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(32, use_bias = False)\n",
    "        self.batch1 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        # preactivation (Recall DenseNet!) -> less resource usage!\n",
    "        #                                     less number of operations!\n",
    "        # weight: 32 X 32 matrix\n",
    "        self.batch2 = tf.keras.layers.BatchNormalization()\n",
    "        self.dense2 = tf.keras.layers.Dense(32, use_bias = False)\n",
    "        \n",
    "        # weight: 64 X 64 matrix (See the concat below call function.)\n",
    "        self.batch3 = tf.keras.layers.BatchNormalization()\n",
    "        self.dense3 = tf.keras.layers.Dense(64, use_bias = False)\n",
    "        \n",
    "        # weight: 128 X 128 matrix\n",
    "        self.batch4 = tf.keras.layers.BatchNormalization()\n",
    "        self.dense4 = tf.keras.layers.Dense(128, use_bias = False)\n",
    "        \n",
    "        self.dense5 = tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "        \n",
    "    def call(self, x, training = False, mask = None):\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.batch1(x, training)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        # preactivation\n",
    "        h = self.batch2(x, training)\n",
    "        h = tf.nn.relu(h)\n",
    "        h = self.dense2(h)\n",
    "        x = tf.concat([x, h], axis = -1)\n",
    "\n",
    "        h = self.batch3(x, training)\n",
    "        h = tf.nn.relu(h)\n",
    "        h = self.dense3(h)\n",
    "        x = tf.concat([x, h], axis = -1)\n",
    "\n",
    "        h = self.batch4(x, training)\n",
    "        h = tf.nn.relu(h)\n",
    "        h = self.dense4(h)\n",
    "        x = tf.concat([x, h], axis = -1)\n",
    "        \n",
    "        return self.dense5(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee0a1585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 24s 12ms/step - loss: 0.5115 - accuracy: 0.8174 - val_loss: 0.5607 - val_accuracy: 0.7876\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.4035 - accuracy: 0.8532 - val_loss: 0.4223 - val_accuracy: 0.8508\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.3740 - accuracy: 0.8617 - val_loss: 0.3788 - val_accuracy: 0.8646\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.3494 - accuracy: 0.8719 - val_loss: 0.3951 - val_accuracy: 0.8605\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.3337 - accuracy: 0.8769 - val_loss: 0.3583 - val_accuracy: 0.8699\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.3229 - accuracy: 0.8814 - val_loss: 0.4083 - val_accuracy: 0.8515\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.3142 - accuracy: 0.8845 - val_loss: 0.3696 - val_accuracy: 0.8692\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.3015 - accuracy: 0.8893 - val_loss: 0.4065 - val_accuracy: 0.8596\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2930 - accuracy: 0.8912 - val_loss: 0.4556 - val_accuracy: 0.8343\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2889 - accuracy: 0.8932 - val_loss: 0.3703 - val_accuracy: 0.8652\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2828 - accuracy: 0.8956 - val_loss: 0.3490 - val_accuracy: 0.8770\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2756 - accuracy: 0.8980 - val_loss: 0.3459 - val_accuracy: 0.8767\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2719 - accuracy: 0.8990 - val_loss: 0.3474 - val_accuracy: 0.8780\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2654 - accuracy: 0.9017 - val_loss: 0.3658 - val_accuracy: 0.8716\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2605 - accuracy: 0.9028 - val_loss: 0.3597 - val_accuracy: 0.8750\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2581 - accuracy: 0.9042 - val_loss: 0.3739 - val_accuracy: 0.8706\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2552 - accuracy: 0.9058 - val_loss: 0.3736 - val_accuracy: 0.8711\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2514 - accuracy: 0.9064 - val_loss: 0.3836 - val_accuracy: 0.8708\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2476 - accuracy: 0.9073 - val_loss: 0.4125 - val_accuracy: 0.8601\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2459 - accuracy: 0.9085 - val_loss: 0.3504 - val_accuracy: 0.8762\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2420 - accuracy: 0.9096 - val_loss: 0.3610 - val_accuracy: 0.8783\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2363 - accuracy: 0.9116 - val_loss: 0.3467 - val_accuracy: 0.8818\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2347 - accuracy: 0.9125 - val_loss: 0.3611 - val_accuracy: 0.8764\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2345 - accuracy: 0.9113 - val_loss: 0.3807 - val_accuracy: 0.8724\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2308 - accuracy: 0.9126 - val_loss: 0.3847 - val_accuracy: 0.8755\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2273 - accuracy: 0.9136 - val_loss: 0.3946 - val_accuracy: 0.8737\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2278 - accuracy: 0.9149 - val_loss: 0.3665 - val_accuracy: 0.8765\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2240 - accuracy: 0.9173 - val_loss: 0.3746 - val_accuracy: 0.8764\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2256 - accuracy: 0.9155 - val_loss: 0.3602 - val_accuracy: 0.8820\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2211 - accuracy: 0.9173 - val_loss: 0.3787 - val_accuracy: 0.8758\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2204 - accuracy: 0.9175 - val_loss: 0.3629 - val_accuracy: 0.8809\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2154 - accuracy: 0.9196 - val_loss: 0.3779 - val_accuracy: 0.8771\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 23s 13ms/step - loss: 0.2156 - accuracy: 0.9194 - val_loss: 0.3638 - val_accuracy: 0.8787\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2144 - accuracy: 0.9197 - val_loss: 0.3572 - val_accuracy: 0.8821\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2118 - accuracy: 0.9208 - val_loss: 0.3577 - val_accuracy: 0.8797\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.2086 - accuracy: 0.9218 - val_loss: 0.3935 - val_accuracy: 0.8684\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2071 - accuracy: 0.9229 - val_loss: 0.3772 - val_accuracy: 0.8770\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2068 - accuracy: 0.9226 - val_loss: 0.3880 - val_accuracy: 0.8737\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2071 - accuracy: 0.9232 - val_loss: 0.3771 - val_accuracy: 0.8782\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2053 - accuracy: 0.9228 - val_loss: 0.4115 - val_accuracy: 0.8720\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2042 - accuracy: 0.9230 - val_loss: 0.4003 - val_accuracy: 0.8679\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2010 - accuracy: 0.9240 - val_loss: 0.3860 - val_accuracy: 0.8777\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2018 - accuracy: 0.9245 - val_loss: 0.3796 - val_accuracy: 0.8808\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2003 - accuracy: 0.9247 - val_loss: 0.3761 - val_accuracy: 0.8802\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2003 - accuracy: 0.9243 - val_loss: 0.3797 - val_accuracy: 0.8859\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1979 - accuracy: 0.9247 - val_loss: 0.3893 - val_accuracy: 0.8813\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1974 - accuracy: 0.9259 - val_loss: 0.4066 - val_accuracy: 0.8744\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1910 - accuracy: 0.9286 - val_loss: 0.4008 - val_accuracy: 0.8755\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1949 - accuracy: 0.9277 - val_loss: 0.4035 - val_accuracy: 0.8774\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1929 - accuracy: 0.9275 - val_loss: 0.3854 - val_accuracy: 0.8814\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1931 - accuracy: 0.9276 - val_loss: 0.3993 - val_accuracy: 0.8778\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1904 - accuracy: 0.9284 - val_loss: 0.4213 - val_accuracy: 0.8712\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1888 - accuracy: 0.9298 - val_loss: 0.4086 - val_accuracy: 0.8761\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1886 - accuracy: 0.9294 - val_loss: 0.4494 - val_accuracy: 0.8648\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1885 - accuracy: 0.9286 - val_loss: 0.3859 - val_accuracy: 0.8865\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1866 - accuracy: 0.9295 - val_loss: 0.4033 - val_accuracy: 0.8753\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.1851 - accuracy: 0.9300 - val_loss: 0.4024 - val_accuracy: 0.8822\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1834 - accuracy: 0.9307 - val_loss: 0.4217 - val_accuracy: 0.8807\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1837 - accuracy: 0.9312 - val_loss: 0.4014 - val_accuracy: 0.8813\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1821 - accuracy: 0.9313 - val_loss: 0.4013 - val_accuracy: 0.8798\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1810 - accuracy: 0.9319 - val_loss: 0.4282 - val_accuracy: 0.8740\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1828 - accuracy: 0.9313 - val_loss: 0.3989 - val_accuracy: 0.8798\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1792 - accuracy: 0.9317 - val_loss: 0.4201 - val_accuracy: 0.8763\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.1814 - accuracy: 0.9311 - val_loss: 0.4384 - val_accuracy: 0.8699\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1755 - accuracy: 0.9346 - val_loss: 0.4378 - val_accuracy: 0.8778\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1785 - accuracy: 0.9327 - val_loss: 0.4244 - val_accuracy: 0.8769\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1758 - accuracy: 0.9331 - val_loss: 0.4344 - val_accuracy: 0.8738\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1745 - accuracy: 0.9336 - val_loss: 0.4196 - val_accuracy: 0.8752\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.1745 - accuracy: 0.9336 - val_loss: 0.4546 - val_accuracy: 0.8692\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1754 - accuracy: 0.9338 - val_loss: 0.4133 - val_accuracy: 0.8794\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1742 - accuracy: 0.9335 - val_loss: 0.4576 - val_accuracy: 0.8698\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.1758 - accuracy: 0.9331 - val_loss: 0.4348 - val_accuracy: 0.8739\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1727 - accuracy: 0.9351 - val_loss: 0.4449 - val_accuracy: 0.8686\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1693 - accuracy: 0.9364 - val_loss: 0.4297 - val_accuracy: 0.8744\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1720 - accuracy: 0.9361 - val_loss: 0.4433 - val_accuracy: 0.8759\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1705 - accuracy: 0.9349 - val_loss: 0.4215 - val_accuracy: 0.8805\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1690 - accuracy: 0.9362 - val_loss: 0.4345 - val_accuracy: 0.8758\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1686 - accuracy: 0.9366 - val_loss: 0.4492 - val_accuracy: 0.8736\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 23s 13ms/step - loss: 0.1676 - accuracy: 0.9372 - val_loss: 0.4348 - val_accuracy: 0.8776\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1683 - accuracy: 0.9366 - val_loss: 0.4697 - val_accuracy: 0.8701\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1691 - accuracy: 0.9370 - val_loss: 0.4175 - val_accuracy: 0.8782\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1686 - accuracy: 0.9367 - val_loss: 0.4444 - val_accuracy: 0.8737\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1658 - accuracy: 0.9380 - val_loss: 0.4751 - val_accuracy: 0.8642\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.1656 - accuracy: 0.9377 - val_loss: 0.4313 - val_accuracy: 0.8774\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1644 - accuracy: 0.9366 - val_loss: 0.4613 - val_accuracy: 0.8708\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1640 - accuracy: 0.9381 - val_loss: 0.4522 - val_accuracy: 0.8672\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1634 - accuracy: 0.9380 - val_loss: 0.4582 - val_accuracy: 0.8712\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1616 - accuracy: 0.9397 - val_loss: 0.4485 - val_accuracy: 0.8704\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1627 - accuracy: 0.9385 - val_loss: 0.4387 - val_accuracy: 0.8769\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1630 - accuracy: 0.9386 - val_loss: 0.4436 - val_accuracy: 0.8755\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.1622 - accuracy: 0.9382 - val_loss: 0.4557 - val_accuracy: 0.8745\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1619 - accuracy: 0.9384 - val_loss: 0.4667 - val_accuracy: 0.8711\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1601 - accuracy: 0.9398 - val_loss: 0.4392 - val_accuracy: 0.8753\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1597 - accuracy: 0.9405 - val_loss: 0.4525 - val_accuracy: 0.8769\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1597 - accuracy: 0.9405 - val_loss: 0.4664 - val_accuracy: 0.8736\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.1577 - accuracy: 0.9401 - val_loss: 0.4667 - val_accuracy: 0.8734\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.1582 - accuracy: 0.9401 - val_loss: 0.4504 - val_accuracy: 0.8771\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.1548 - accuracy: 0.9414 - val_loss: 0.4499 - val_accuracy: 0.8765\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.1565 - accuracy: 0.9409 - val_loss: 0.4432 - val_accuracy: 0.8737\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.1551 - accuracy: 0.9429 - val_loss: 0.4856 - val_accuracy: 0.8713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21447239190>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "model4 = MyModel_Under()\n",
    "model4.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "model4.fit(train_ds, validation_data = test_ds, epochs = EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c029c1f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fea79587",
   "metadata": {},
   "source": [
    "# Imbalanced Data Problem\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0073ef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel_Aug(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel_Aug, self).__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(1024, activation = 'relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "        \n",
    "    def call(self, x, training = False, mask = None):\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        \n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd3d9588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "cifar10 = tf.keras.datasets.cifar10 # 32 X 32 X 3 video (10 classes)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "\n",
    "# imbalanced small dataset\n",
    "import random\n",
    "\n",
    "# training set\n",
    "x_train_small = list() # Its elements are batches.\n",
    "y_train_small = list()\n",
    "\n",
    "for x, y in zip(x_train, y_train):\n",
    "    # Use only 10% data if labels are 0. -> Intentionally, generate small size class.\n",
    "    # Use 100% data if labels are 1.\n",
    "    if (y == 0 and random.randint(0, 100) < 10) or y == 1:\n",
    "        x_train_small.append(x[:]) # flattenning! (Our network is shallow.)\n",
    "        y_train_small.append(y)\n",
    "        \n",
    "# test set\n",
    "x_test_small = list()\n",
    "y_test_small = list()\n",
    "\n",
    "for x, y in zip(x_test, y_test):\n",
    "    # The test set must be extracted fairly.\n",
    "    if y == 0 or y == 1:\n",
    "        x_test_small.append(x[:])\n",
    "        y_test_small.append(y)\n",
    "        \n",
    "# Convert the manipulated data into NumPy arrays..\n",
    "x_train = np.stack(x_train_small, axis = 0)\n",
    "y_train = np.stack(y_train_small, axis = 0)\n",
    "x_test = np.stack(x_test_small, axis = 0)\n",
    "y_test = np.stack(y_test_small, axis = 0)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(32).prefetch(2048)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_test, y_test)).batch(32).prefetch(2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a70cad5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.4258 - accuracy: 0.9028 - precision: 0.9152 - recall: 0.9840 - val_loss: 0.8537 - val_accuracy: 0.5850 - val_precision: 0.5473 - val_recall: 0.9830\n",
      "Epoch 2/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.2782 - accuracy: 0.9059 - precision: 0.9236 - recall: 0.9770 - val_loss: 0.7234 - val_accuracy: 0.6140 - val_precision: 0.5654 - val_recall: 0.9850\n",
      "Epoch 3/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.2297 - accuracy: 0.9175 - precision: 0.9285 - recall: 0.9848 - val_loss: 1.2338 - val_accuracy: 0.5445 - val_precision: 0.5234 - val_recall: 0.9940\n",
      "Epoch 4/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.2325 - accuracy: 0.9173 - precision: 0.9316 - recall: 0.9808 - val_loss: 0.8245 - val_accuracy: 0.6380 - val_precision: 0.5813 - val_recall: 0.9870\n",
      "Epoch 5/100\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.2102 - accuracy: 0.9271 - precision: 0.9399 - recall: 0.9824 - val_loss: 0.5433 - val_accuracy: 0.7565 - val_precision: 0.6803 - val_recall: 0.9680\n",
      "Epoch 6/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.2099 - accuracy: 0.9268 - precision: 0.9387 - recall: 0.9834 - val_loss: 0.4757 - val_accuracy: 0.8020 - val_precision: 0.7330 - val_recall: 0.9500\n",
      "Epoch 7/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.1997 - accuracy: 0.9315 - precision: 0.9456 - recall: 0.9808 - val_loss: 0.8732 - val_accuracy: 0.6370 - val_precision: 0.5802 - val_recall: 0.9910\n",
      "Epoch 8/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.1894 - accuracy: 0.9331 - precision: 0.9459 - recall: 0.9824 - val_loss: 0.4999 - val_accuracy: 0.7940 - val_precision: 0.7211 - val_recall: 0.9590\n",
      "Epoch 9/100\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.1890 - accuracy: 0.9311 - precision: 0.9446 - recall: 0.9816 - val_loss: 0.7438 - val_accuracy: 0.6935 - val_precision: 0.6224 - val_recall: 0.9840\n",
      "Epoch 10/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.1798 - accuracy: 0.9366 - precision: 0.9502 - recall: 0.9814 - val_loss: 0.4422 - val_accuracy: 0.8200 - val_precision: 0.7649 - val_recall: 0.9240\n",
      "Epoch 11/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.1679 - accuracy: 0.9391 - precision: 0.9504 - recall: 0.9842 - val_loss: 0.9359 - val_accuracy: 0.6570 - val_precision: 0.5941 - val_recall: 0.9910\n",
      "Epoch 12/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.1677 - accuracy: 0.9393 - precision: 0.9514 - recall: 0.9832 - val_loss: 0.4509 - val_accuracy: 0.8200 - val_precision: 0.7544 - val_recall: 0.9490\n",
      "Epoch 13/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.1653 - accuracy: 0.9402 - precision: 0.9516 - recall: 0.9840 - val_loss: 0.5293 - val_accuracy: 0.7820 - val_precision: 0.7058 - val_recall: 0.9670\n",
      "Epoch 14/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.1516 - accuracy: 0.9456 - precision: 0.9544 - recall: 0.9872 - val_loss: 0.5047 - val_accuracy: 0.7990 - val_precision: 0.7241 - val_recall: 0.9660\n",
      "Epoch 15/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.1572 - accuracy: 0.9407 - precision: 0.9545 - recall: 0.9814 - val_loss: 0.8592 - val_accuracy: 0.6755 - val_precision: 0.6072 - val_recall: 0.9940\n",
      "Epoch 16/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.1435 - accuracy: 0.9449 - precision: 0.9563 - recall: 0.9842 - val_loss: 0.7513 - val_accuracy: 0.7045 - val_precision: 0.6303 - val_recall: 0.9890\n",
      "Epoch 17/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.1483 - accuracy: 0.9453 - precision: 0.9561 - recall: 0.9848 - val_loss: 0.7783 - val_accuracy: 0.6980 - val_precision: 0.6248 - val_recall: 0.9910\n",
      "Epoch 18/100\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.1341 - accuracy: 0.9498 - precision: 0.9592 - recall: 0.9866 - val_loss: 0.6317 - val_accuracy: 0.7665 - val_precision: 0.6862 - val_recall: 0.9820\n",
      "Epoch 19/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.1329 - accuracy: 0.9523 - precision: 0.9636 - recall: 0.9846 - val_loss: 0.9394 - val_accuracy: 0.6600 - val_precision: 0.5962 - val_recall: 0.9920\n",
      "Epoch 20/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.1363 - accuracy: 0.9496 - precision: 0.9610 - recall: 0.9844 - val_loss: 0.4781 - val_accuracy: 0.8255 - val_precision: 0.7577 - val_recall: 0.9570\n",
      "Epoch 21/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.1246 - accuracy: 0.9509 - precision: 0.9632 - recall: 0.9834 - val_loss: 0.7332 - val_accuracy: 0.7575 - val_precision: 0.6775 - val_recall: 0.9830\n",
      "Epoch 22/100\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.1168 - accuracy: 0.9574 - precision: 0.9680 - recall: 0.9856 - val_loss: 0.6756 - val_accuracy: 0.7410 - val_precision: 0.6628 - val_recall: 0.9810\n",
      "Epoch 23/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.1131 - accuracy: 0.9569 - precision: 0.9670 - recall: 0.9860 - val_loss: 0.5476 - val_accuracy: 0.8175 - val_precision: 0.7452 - val_recall: 0.9650\n",
      "Epoch 24/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.1067 - accuracy: 0.9603 - precision: 0.9712 - recall: 0.9854 - val_loss: 0.6090 - val_accuracy: 0.7810 - val_precision: 0.7016 - val_recall: 0.9780\n",
      "Epoch 25/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.1038 - accuracy: 0.9603 - precision: 0.9708 - recall: 0.9858 - val_loss: 0.5814 - val_accuracy: 0.7980 - val_precision: 0.7207 - val_recall: 0.9730\n",
      "Epoch 26/100\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.0986 - accuracy: 0.9616 - precision: 0.9718 - recall: 0.9862 - val_loss: 0.7646 - val_accuracy: 0.7345 - val_precision: 0.6554 - val_recall: 0.9890\n",
      "Epoch 27/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.1012 - accuracy: 0.9601 - precision: 0.9718 - recall: 0.9846 - val_loss: 1.2850 - val_accuracy: 0.6370 - val_precision: 0.5795 - val_recall: 0.9990\n",
      "Epoch 28/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.1003 - accuracy: 0.9590 - precision: 0.9695 - recall: 0.9858 - val_loss: 0.7714 - val_accuracy: 0.7590 - val_precision: 0.6784 - val_recall: 0.9850\n",
      "Epoch 29/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0918 - accuracy: 0.9641 - precision: 0.9736 - recall: 0.9872 - val_loss: 0.5783 - val_accuracy: 0.8080 - val_precision: 0.7340 - val_recall: 0.9660\n",
      "Epoch 30/100\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.0852 - accuracy: 0.9666 - precision: 0.9757 - recall: 0.9878 - val_loss: 0.6437 - val_accuracy: 0.8065 - val_precision: 0.7296 - val_recall: 0.9740\n",
      "Epoch 31/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.0876 - accuracy: 0.9659 - precision: 0.9762 - recall: 0.9864 - val_loss: 0.9134 - val_accuracy: 0.7315 - val_precision: 0.6526 - val_recall: 0.9900\n",
      "Epoch 32/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0824 - accuracy: 0.9685 - precision: 0.9778 - recall: 0.9876 - val_loss: 0.7101 - val_accuracy: 0.7820 - val_precision: 0.7026 - val_recall: 0.9780\n",
      "Epoch 33/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0846 - accuracy: 0.9656 - precision: 0.9757 - recall: 0.9866 - val_loss: 0.6203 - val_accuracy: 0.8090 - val_precision: 0.7330 - val_recall: 0.9720\n",
      "Epoch 34/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.0756 - accuracy: 0.9714 - precision: 0.9786 - recall: 0.9900 - val_loss: 0.4403 - val_accuracy: 0.8490 - val_precision: 0.7988 - val_recall: 0.9330\n",
      "Epoch 35/100\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.0865 - accuracy: 0.9677 - precision: 0.9778 - recall: 0.9868 - val_loss: 1.0186 - val_accuracy: 0.7345 - val_precision: 0.6550 - val_recall: 0.9910\n",
      "Epoch 36/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.0819 - accuracy: 0.9681 - precision: 0.9788 - recall: 0.9862 - val_loss: 0.6901 - val_accuracy: 0.8045 - val_precision: 0.7257 - val_recall: 0.9790\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0661 - accuracy: 0.9750 - precision: 0.9825 - recall: 0.9900 - val_loss: 0.8275 - val_accuracy: 0.7685 - val_precision: 0.6887 - val_recall: 0.9800\n",
      "Epoch 38/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.0786 - accuracy: 0.9708 - precision: 0.9800 - recall: 0.9880 - val_loss: 0.5605 - val_accuracy: 0.8295 - val_precision: 0.7580 - val_recall: 0.9680\n",
      "Epoch 39/100\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.0635 - accuracy: 0.9772 - precision: 0.9837 - recall: 0.9912 - val_loss: 1.0375 - val_accuracy: 0.7410 - val_precision: 0.6607 - val_recall: 0.9910\n",
      "Epoch 40/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0653 - accuracy: 0.9763 - precision: 0.9829 - recall: 0.9910 - val_loss: 1.0126 - val_accuracy: 0.7395 - val_precision: 0.6600 - val_recall: 0.9880\n",
      "Epoch 41/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0601 - accuracy: 0.9768 - precision: 0.9843 - recall: 0.9902 - val_loss: 0.6048 - val_accuracy: 0.8315 - val_precision: 0.7608 - val_recall: 0.9670\n",
      "Epoch 42/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.0686 - accuracy: 0.9721 - precision: 0.9811 - recall: 0.9882 - val_loss: 0.8615 - val_accuracy: 0.7705 - val_precision: 0.6893 - val_recall: 0.9850\n",
      "Epoch 43/100\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.0722 - accuracy: 0.9724 - precision: 0.9813 - recall: 0.9884 - val_loss: 0.8761 - val_accuracy: 0.7705 - val_precision: 0.6909 - val_recall: 0.9790\n",
      "Epoch 44/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0656 - accuracy: 0.9735 - precision: 0.9831 - recall: 0.9878 - val_loss: 0.6722 - val_accuracy: 0.8235 - val_precision: 0.7498 - val_recall: 0.9710\n",
      "Epoch 45/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.0458 - accuracy: 0.9831 - precision: 0.9881 - recall: 0.9934 - val_loss: 1.1019 - val_accuracy: 0.7580 - val_precision: 0.6767 - val_recall: 0.9880\n",
      "Epoch 46/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0653 - accuracy: 0.9772 - precision: 0.9851 - recall: 0.9898 - val_loss: 0.7240 - val_accuracy: 0.8105 - val_precision: 0.7315 - val_recall: 0.9810\n",
      "Epoch 47/100\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.0609 - accuracy: 0.9775 - precision: 0.9845 - recall: 0.9908 - val_loss: 0.8893 - val_accuracy: 0.7735 - val_precision: 0.6927 - val_recall: 0.9830\n",
      "Epoch 48/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.0488 - accuracy: 0.9804 - precision: 0.9878 - recall: 0.9906 - val_loss: 0.9057 - val_accuracy: 0.7835 - val_precision: 0.7024 - val_recall: 0.9840\n",
      "Epoch 49/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0458 - accuracy: 0.9839 - precision: 0.9894 - recall: 0.9928 - val_loss: 0.7746 - val_accuracy: 0.8160 - val_precision: 0.7401 - val_recall: 0.9740\n",
      "Epoch 50/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.0449 - accuracy: 0.9835 - precision: 0.9887 - recall: 0.9932 - val_loss: 0.8456 - val_accuracy: 0.7985 - val_precision: 0.7213 - val_recall: 0.9730\n",
      "Epoch 51/100\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.0558 - accuracy: 0.9773 - precision: 0.9845 - recall: 0.9906 - val_loss: 0.7970 - val_accuracy: 0.8110 - val_precision: 0.7335 - val_recall: 0.9770\n",
      "Epoch 52/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.0426 - accuracy: 0.9846 - precision: 0.9898 - recall: 0.9932 - val_loss: 0.9699 - val_accuracy: 0.7760 - val_precision: 0.6946 - val_recall: 0.9850\n",
      "Epoch 53/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.0477 - accuracy: 0.9801 - precision: 0.9859 - recall: 0.9922 - val_loss: 0.5163 - val_accuracy: 0.8525 - val_precision: 0.7950 - val_recall: 0.9500\n",
      "Epoch 54/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0491 - accuracy: 0.9815 - precision: 0.9877 - recall: 0.9920 - val_loss: 0.9914 - val_accuracy: 0.7770 - val_precision: 0.6959 - val_recall: 0.9840\n",
      "Epoch 55/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.0429 - accuracy: 0.9831 - precision: 0.9886 - recall: 0.9928 - val_loss: 0.9618 - val_accuracy: 0.7865 - val_precision: 0.7066 - val_recall: 0.9800\n",
      "Epoch 56/100\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.0342 - accuracy: 0.9875 - precision: 0.9910 - recall: 0.9952 - val_loss: 0.8250 - val_accuracy: 0.8205 - val_precision: 0.7445 - val_recall: 0.9760\n",
      "Epoch 57/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0405 - accuracy: 0.9846 - precision: 0.9902 - recall: 0.9928 - val_loss: 0.5751 - val_accuracy: 0.8390 - val_precision: 0.7792 - val_recall: 0.9460\n",
      "Epoch 58/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0478 - accuracy: 0.9811 - precision: 0.9878 - recall: 0.9914 - val_loss: 0.9096 - val_accuracy: 0.8025 - val_precision: 0.7246 - val_recall: 0.9760\n",
      "Epoch 59/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.0328 - accuracy: 0.9886 - precision: 0.9924 - recall: 0.9950 - val_loss: 0.7992 - val_accuracy: 0.8285 - val_precision: 0.7564 - val_recall: 0.9690\n",
      "Epoch 60/100\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.0296 - accuracy: 0.9891 - precision: 0.9936 - recall: 0.9944 - val_loss: 1.3195 - val_accuracy: 0.7500 - val_precision: 0.6696 - val_recall: 0.9870\n",
      "Epoch 61/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0599 - accuracy: 0.9753 - precision: 0.9845 - recall: 0.9884 - val_loss: 0.9375 - val_accuracy: 0.7885 - val_precision: 0.7083 - val_recall: 0.9810\n",
      "Epoch 62/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0406 - accuracy: 0.9868 - precision: 0.9920 - recall: 0.9934 - val_loss: 1.0279 - val_accuracy: 0.7940 - val_precision: 0.7143 - val_recall: 0.9800\n",
      "Epoch 63/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.0251 - accuracy: 0.9902 - precision: 0.9934 - recall: 0.9958 - val_loss: 0.9805 - val_accuracy: 0.8055 - val_precision: 0.7251 - val_recall: 0.9840\n",
      "Epoch 64/100\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.0948 - accuracy: 0.9676 - precision: 0.9803 - recall: 0.9840 - val_loss: 1.0655 - val_accuracy: 0.7575 - val_precision: 0.6765 - val_recall: 0.9870\n",
      "Epoch 65/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0347 - accuracy: 0.9868 - precision: 0.9908 - recall: 0.9946 - val_loss: 0.8552 - val_accuracy: 0.8130 - val_precision: 0.7360 - val_recall: 0.9760\n",
      "Epoch 66/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.0357 - accuracy: 0.9871 - precision: 0.9906 - recall: 0.9952 - val_loss: 0.6949 - val_accuracy: 0.8390 - val_precision: 0.7703 - val_recall: 0.9660\n",
      "Epoch 67/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0307 - accuracy: 0.9898 - precision: 0.9934 - recall: 0.9954 - val_loss: 0.8452 - val_accuracy: 0.8180 - val_precision: 0.7431 - val_recall: 0.9720\n",
      "Epoch 68/100\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.0251 - accuracy: 0.9918 - precision: 0.9944 - recall: 0.9966 - val_loss: 0.8593 - val_accuracy: 0.8120 - val_precision: 0.7356 - val_recall: 0.9740\n",
      "Epoch 69/100\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.0246 - accuracy: 0.9915 - precision: 0.9946 - recall: 0.9960 - val_loss: 1.4080 - val_accuracy: 0.7345 - val_precision: 0.6546 - val_recall: 0.9930\n",
      "Epoch 70/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0382 - accuracy: 0.9860 - precision: 0.9918 - recall: 0.9928 - val_loss: 0.8019 - val_accuracy: 0.8290 - val_precision: 0.7582 - val_recall: 0.9660\n",
      "Epoch 71/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0346 - accuracy: 0.9882 - precision: 0.9940 - recall: 0.9930 - val_loss: 0.9658 - val_accuracy: 0.8060 - val_precision: 0.7267 - val_recall: 0.9810\n",
      "Epoch 72/100\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.0201 - accuracy: 0.9929 - precision: 0.9952 - recall: 0.9970 - val_loss: 0.7242 - val_accuracy: 0.8360 - val_precision: 0.7745 - val_recall: 0.9480\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/173 [==============================] - 1s 9ms/step - loss: 0.0258 - accuracy: 0.9906 - precision: 0.9948 - recall: 0.9948 - val_loss: 0.8942 - val_accuracy: 0.8150 - val_precision: 0.7442 - val_recall: 0.9600\n",
      "Epoch 74/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0297 - accuracy: 0.9891 - precision: 0.9940 - recall: 0.9940 - val_loss: 1.2201 - val_accuracy: 0.7730 - val_precision: 0.6931 - val_recall: 0.9800\n",
      "Epoch 75/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0181 - accuracy: 0.9937 - precision: 0.9954 - recall: 0.9976 - val_loss: 0.8676 - val_accuracy: 0.8260 - val_precision: 0.7527 - val_recall: 0.9710\n",
      "Epoch 76/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.0405 - accuracy: 0.9862 - precision: 0.9930 - recall: 0.9918 - val_loss: 0.6761 - val_accuracy: 0.8295 - val_precision: 0.7998 - val_recall: 0.8790\n",
      "Epoch 77/100\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.0311 - accuracy: 0.9882 - precision: 0.9926 - recall: 0.9944 - val_loss: 1.1134 - val_accuracy: 0.8070 - val_precision: 0.7267 - val_recall: 0.9840\n",
      "Epoch 78/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.0146 - accuracy: 0.9958 - precision: 0.9974 - recall: 0.9980 - val_loss: 1.0352 - val_accuracy: 0.8155 - val_precision: 0.7385 - val_recall: 0.9770\n",
      "Epoch 79/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0147 - accuracy: 0.9951 - precision: 0.9974 - recall: 0.9972 - val_loss: 0.7643 - val_accuracy: 0.8480 - val_precision: 0.7848 - val_recall: 0.9590\n",
      "Epoch 80/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.0186 - accuracy: 0.9931 - precision: 0.9960 - recall: 0.9964 - val_loss: 1.0190 - val_accuracy: 0.8190 - val_precision: 0.7417 - val_recall: 0.9790\n",
      "Epoch 81/100\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.0164 - accuracy: 0.9953 - precision: 0.9964 - recall: 0.9984 - val_loss: 1.5527 - val_accuracy: 0.7640 - val_precision: 0.6828 - val_recall: 0.9860\n",
      "Epoch 82/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0377 - accuracy: 0.9855 - precision: 0.9916 - recall: 0.9924 - val_loss: 0.9554 - val_accuracy: 0.8250 - val_precision: 0.7523 - val_recall: 0.9690\n",
      "Epoch 83/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0405 - accuracy: 0.9855 - precision: 0.9908 - recall: 0.9932 - val_loss: 1.1050 - val_accuracy: 0.8025 - val_precision: 0.7232 - val_recall: 0.9800\n",
      "Epoch 84/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0161 - accuracy: 0.9938 - precision: 0.9964 - recall: 0.9968 - val_loss: 1.1410 - val_accuracy: 0.8030 - val_precision: 0.7244 - val_recall: 0.9780\n",
      "Epoch 85/100\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.0151 - accuracy: 0.9951 - precision: 0.9970 - recall: 0.9976 - val_loss: 1.2861 - val_accuracy: 0.7905 - val_precision: 0.7094 - val_recall: 0.9840\n",
      "Epoch 86/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0111 - accuracy: 0.9973 - precision: 0.9982 - recall: 0.9988 - val_loss: 1.3883 - val_accuracy: 0.7810 - val_precision: 0.7004 - val_recall: 0.9820\n",
      "Epoch 87/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0171 - accuracy: 0.9937 - precision: 0.9958 - recall: 0.9972 - val_loss: 1.3397 - val_accuracy: 0.7980 - val_precision: 0.7182 - val_recall: 0.9810\n",
      "Epoch 88/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0160 - accuracy: 0.9940 - precision: 0.9964 - recall: 0.9970 - val_loss: 1.0053 - val_accuracy: 0.8195 - val_precision: 0.7456 - val_recall: 0.9700\n",
      "Epoch 89/100\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.0107 - accuracy: 0.9975 - precision: 0.9986 - recall: 0.9986 - val_loss: 1.6145 - val_accuracy: 0.7615 - val_precision: 0.6797 - val_recall: 0.9890\n",
      "Epoch 90/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0178 - accuracy: 0.9938 - precision: 0.9966 - recall: 0.9966 - val_loss: 1.2307 - val_accuracy: 0.7940 - val_precision: 0.7152 - val_recall: 0.9770\n",
      "Epoch 91/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.0135 - accuracy: 0.9947 - precision: 0.9966 - recall: 0.9976 - val_loss: 0.8953 - val_accuracy: 0.8350 - val_precision: 0.7659 - val_recall: 0.9650\n",
      "Epoch 92/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.0328 - accuracy: 0.9871 - precision: 0.9924 - recall: 0.9934 - val_loss: 1.1331 - val_accuracy: 0.8015 - val_precision: 0.7232 - val_recall: 0.9770\n",
      "Epoch 93/100\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.0301 - accuracy: 0.9895 - precision: 0.9928 - recall: 0.9956 - val_loss: 0.9865 - val_accuracy: 0.8300 - val_precision: 0.7632 - val_recall: 0.9570\n",
      "Epoch 94/100\n",
      "173/173 [==============================] - 1s 9ms/step - loss: 0.0188 - accuracy: 0.9926 - precision: 0.9956 - recall: 0.9962 - val_loss: 1.0910 - val_accuracy: 0.8160 - val_precision: 0.7431 - val_recall: 0.9660\n",
      "Epoch 95/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0145 - accuracy: 0.9960 - precision: 0.9982 - recall: 0.9974 - val_loss: 1.3845 - val_accuracy: 0.7980 - val_precision: 0.7178 - val_recall: 0.9820\n",
      "Epoch 96/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0232 - accuracy: 0.9918 - precision: 0.9950 - recall: 0.9960 - val_loss: 0.9632 - val_accuracy: 0.8245 - val_precision: 0.7517 - val_recall: 0.9690\n",
      "Epoch 97/100\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.0646 - accuracy: 0.9779 - precision: 0.9880 - recall: 0.9876 - val_loss: 1.2514 - val_accuracy: 0.7740 - val_precision: 0.6932 - val_recall: 0.9830\n",
      "Epoch 98/100\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.0255 - accuracy: 0.9920 - precision: 0.9950 - recall: 0.9962 - val_loss: 0.7401 - val_accuracy: 0.8570 - val_precision: 0.8143 - val_recall: 0.9250\n",
      "Epoch 99/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0316 - accuracy: 0.9877 - precision: 0.9930 - recall: 0.9934 - val_loss: 1.3258 - val_accuracy: 0.7885 - val_precision: 0.7092 - val_recall: 0.9780\n",
      "Epoch 100/100\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.0242 - accuracy: 0.9918 - precision: 0.9944 - recall: 0.9966 - val_loss: 1.0559 - val_accuracy: 0.8220 - val_precision: 0.7473 - val_recall: 0.9730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x214450306d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "model5 = MyModel_Aug()\n",
    "model5.compile(optimizer = 'adam',\n",
    "               loss = 'binary_crossentropy',\n",
    "               # Precision and Recall are useful to detect the problem\n",
    "               # caused by the model which ignores imbalanced data.\n",
    "               metrics = ['accuracy',\n",
    "                          tf.keras.metrics.Precision(name = 'precision'),\n",
    "                          tf.keras.metrics.Recall(name = 'recall')])\n",
    "model5.fit(train_ds, validation_data = test_ds, epochs = EPOCHS)\n",
    "\n",
    "# Note that the validation precision is almost much less thant\n",
    "# that of training,\n",
    "# which indicates an imblanced data problem.\n",
    "# (invariant training loss over epochs.. no training improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15975fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\programdata\\miniconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\programdata\\miniconda3\\lib\\site-packages (from imblearn) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\programdata\\miniconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.22.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.8.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\miniconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6dd03982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying BorderlineSMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "# instantiating SMOTE\n",
    "smote = BorderlineSMOTE()\n",
    "\n",
    "# Convert the shape of data. (from 4-dimensional to 2-dimensional)\n",
    "# Note that our model is fully connected layers not CNN.\n",
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1] * x_train.shape[2] * x_train.shape[3])).astype(np.float32)\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1] * x_test.shape[2] * x_test.shape[3])).astype(np.float32)\n",
    "\n",
    "x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(32).prefetch(2048)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_test, y_test)).batch(32).prefetch(2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e002d15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.5616 - accuracy: 0.7491 - precision: 0.7601 - recall: 0.7280 - val_loss: 0.4419 - val_accuracy: 0.8150 - val_precision: 0.8387 - val_recall: 0.7800\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.4233 - accuracy: 0.8129 - precision: 0.8287 - recall: 0.7888 - val_loss: 0.5645 - val_accuracy: 0.7565 - val_precision: 0.6942 - val_recall: 0.9170\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.3333 - accuracy: 0.8623 - precision: 0.8863 - recall: 0.8312 - val_loss: 0.5580 - val_accuracy: 0.7555 - val_precision: 0.9237 - val_recall: 0.5570\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.2707 - accuracy: 0.8955 - precision: 0.9230 - recall: 0.8630 - val_loss: 0.4739 - val_accuracy: 0.8180 - val_precision: 0.7686 - val_recall: 0.9100\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.2303 - accuracy: 0.9147 - precision: 0.9387 - recall: 0.8874 - val_loss: 0.4201 - val_accuracy: 0.8245 - val_precision: 0.8602 - val_recall: 0.7750\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.2007 - accuracy: 0.9278 - precision: 0.9471 - recall: 0.9062 - val_loss: 0.4656 - val_accuracy: 0.8240 - val_precision: 0.8000 - val_recall: 0.8640\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1684 - accuracy: 0.9423 - precision: 0.9612 - recall: 0.9218 - val_loss: 0.4438 - val_accuracy: 0.8450 - val_precision: 0.8097 - val_recall: 0.9020\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1468 - accuracy: 0.9506 - precision: 0.9665 - recall: 0.9336 - val_loss: 0.4567 - val_accuracy: 0.8350 - val_precision: 0.8363 - val_recall: 0.8330\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1356 - accuracy: 0.9523 - precision: 0.9658 - recall: 0.9378 - val_loss: 0.4541 - val_accuracy: 0.8455 - val_precision: 0.8256 - val_recall: 0.8760\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1328 - accuracy: 0.9545 - precision: 0.9683 - recall: 0.9398 - val_loss: 0.5006 - val_accuracy: 0.8410 - val_precision: 0.7955 - val_recall: 0.9180\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1169 - accuracy: 0.9612 - precision: 0.9747 - recall: 0.9470 - val_loss: 0.8107 - val_accuracy: 0.7850 - val_precision: 0.7059 - val_recall: 0.9770\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0911 - accuracy: 0.9706 - precision: 0.9822 - recall: 0.9586 - val_loss: 0.4609 - val_accuracy: 0.8480 - val_precision: 0.8566 - val_recall: 0.8360\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0913 - accuracy: 0.9697 - precision: 0.9802 - recall: 0.9588 - val_loss: 0.4895 - val_accuracy: 0.8530 - val_precision: 0.8215 - val_recall: 0.9020\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0805 - accuracy: 0.9738 - precision: 0.9841 - recall: 0.9632 - val_loss: 0.7370 - val_accuracy: 0.8130 - val_precision: 0.7449 - val_recall: 0.9520\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0737 - accuracy: 0.9763 - precision: 0.9849 - recall: 0.9674 - val_loss: 0.7380 - val_accuracy: 0.8305 - val_precision: 0.7685 - val_recall: 0.9460\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0708 - accuracy: 0.9763 - precision: 0.9839 - recall: 0.9684 - val_loss: 0.6731 - val_accuracy: 0.8370 - val_precision: 0.7758 - val_recall: 0.9480\n",
      "Epoch 17/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0689 - accuracy: 0.9768 - precision: 0.9842 - recall: 0.9692 - val_loss: 0.7983 - val_accuracy: 0.8175 - val_precision: 0.7448 - val_recall: 0.9660\n",
      "Epoch 18/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0595 - accuracy: 0.9803 - precision: 0.9860 - recall: 0.9744 - val_loss: 0.6614 - val_accuracy: 0.8430 - val_precision: 0.7802 - val_recall: 0.9550\n",
      "Epoch 19/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0566 - accuracy: 0.9819 - precision: 0.9888 - recall: 0.9748 - val_loss: 0.7993 - val_accuracy: 0.8285 - val_precision: 0.7564 - val_recall: 0.9690\n",
      "Epoch 20/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0651 - accuracy: 0.9778 - precision: 0.9850 - recall: 0.9704 - val_loss: 0.7277 - val_accuracy: 0.8255 - val_precision: 0.7666 - val_recall: 0.9360\n",
      "Epoch 21/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0477 - accuracy: 0.9841 - precision: 0.9895 - recall: 0.9786 - val_loss: 0.6862 - val_accuracy: 0.8470 - val_precision: 0.8039 - val_recall: 0.9180\n",
      "Epoch 22/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0436 - accuracy: 0.9865 - precision: 0.9915 - recall: 0.9814 - val_loss: 0.6415 - val_accuracy: 0.8455 - val_precision: 0.7976 - val_recall: 0.9260\n",
      "Epoch 23/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0621 - accuracy: 0.9797 - precision: 0.9858 - recall: 0.9734 - val_loss: 1.6155 - val_accuracy: 0.7375 - val_precision: 0.6576 - val_recall: 0.9910\n",
      "Epoch 24/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0502 - accuracy: 0.9831 - precision: 0.9879 - recall: 0.9782 - val_loss: 1.0342 - val_accuracy: 0.8200 - val_precision: 0.7454 - val_recall: 0.9720\n",
      "Epoch 25/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0380 - accuracy: 0.9875 - precision: 0.9913 - recall: 0.9836 - val_loss: 0.8819 - val_accuracy: 0.8245 - val_precision: 0.7549 - val_recall: 0.9610\n",
      "Epoch 26/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0332 - accuracy: 0.9900 - precision: 0.9932 - recall: 0.9868 - val_loss: 0.9986 - val_accuracy: 0.8215 - val_precision: 0.7464 - val_recall: 0.9740\n",
      "Epoch 27/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0398 - accuracy: 0.9859 - precision: 0.9881 - recall: 0.9836 - val_loss: 0.6137 - val_accuracy: 0.8410 - val_precision: 0.8266 - val_recall: 0.8630\n",
      "Epoch 28/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0372 - accuracy: 0.9875 - precision: 0.9911 - recall: 0.9838 - val_loss: 0.8360 - val_accuracy: 0.8320 - val_precision: 0.7708 - val_recall: 0.9450\n",
      "Epoch 29/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0292 - accuracy: 0.9906 - precision: 0.9940 - recall: 0.9872 - val_loss: 0.7704 - val_accuracy: 0.8505 - val_precision: 0.7909 - val_recall: 0.9530\n",
      "Epoch 30/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0412 - accuracy: 0.9864 - precision: 0.9899 - recall: 0.9828 - val_loss: 0.7696 - val_accuracy: 0.8340 - val_precision: 0.7909 - val_recall: 0.9080\n",
      "Epoch 31/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0309 - accuracy: 0.9898 - precision: 0.9926 - recall: 0.9870 - val_loss: 1.0562 - val_accuracy: 0.8160 - val_precision: 0.7431 - val_recall: 0.9660\n",
      "Epoch 32/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0350 - accuracy: 0.9878 - precision: 0.9896 - recall: 0.9860 - val_loss: 1.5340 - val_accuracy: 0.7800 - val_precision: 0.6986 - val_recall: 0.9850\n",
      "Epoch 33/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0365 - accuracy: 0.9877 - precision: 0.9903 - recall: 0.9850 - val_loss: 0.9709 - val_accuracy: 0.8305 - val_precision: 0.7633 - val_recall: 0.9580\n",
      "Epoch 34/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0245 - accuracy: 0.9919 - precision: 0.9934 - recall: 0.9904 - val_loss: 1.4316 - val_accuracy: 0.7975 - val_precision: 0.7157 - val_recall: 0.9870\n",
      "Epoch 35/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0378 - accuracy: 0.9873 - precision: 0.9894 - recall: 0.9852 - val_loss: 0.9633 - val_accuracy: 0.8335 - val_precision: 0.7700 - val_recall: 0.9510\n",
      "Epoch 36/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0206 - accuracy: 0.9929 - precision: 0.9948 - recall: 0.9910 - val_loss: 0.9142 - val_accuracy: 0.8440 - val_precision: 0.7829 - val_recall: 0.9520\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0217 - accuracy: 0.9932 - precision: 0.9946 - recall: 0.9918 - val_loss: 0.8696 - val_accuracy: 0.8650 - val_precision: 0.8219 - val_recall: 0.9320\n",
      "Epoch 38/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0177 - accuracy: 0.9939 - precision: 0.9960 - recall: 0.9918 - val_loss: 0.9625 - val_accuracy: 0.8405 - val_precision: 0.7766 - val_recall: 0.9560\n",
      "Epoch 39/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0542 - accuracy: 0.9806 - precision: 0.9835 - recall: 0.9776 - val_loss: 1.1798 - val_accuracy: 0.8235 - val_precision: 0.7506 - val_recall: 0.9690\n",
      "Epoch 40/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0299 - accuracy: 0.9900 - precision: 0.9922 - recall: 0.9878 - val_loss: 1.0702 - val_accuracy: 0.8390 - val_precision: 0.7699 - val_recall: 0.9670\n",
      "Epoch 41/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0199 - accuracy: 0.9941 - precision: 0.9954 - recall: 0.9928 - val_loss: 1.3446 - val_accuracy: 0.8070 - val_precision: 0.7277 - val_recall: 0.9810\n",
      "Epoch 42/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0163 - accuracy: 0.9947 - precision: 0.9964 - recall: 0.9930 - val_loss: 1.0388 - val_accuracy: 0.8265 - val_precision: 0.7631 - val_recall: 0.9470\n",
      "Epoch 43/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0178 - accuracy: 0.9943 - precision: 0.9956 - recall: 0.9930 - val_loss: 1.0869 - val_accuracy: 0.8310 - val_precision: 0.7704 - val_recall: 0.9430\n",
      "Epoch 44/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0267 - accuracy: 0.9901 - precision: 0.9930 - recall: 0.9872 - val_loss: 1.2381 - val_accuracy: 0.8130 - val_precision: 0.7415 - val_recall: 0.9610\n",
      "Epoch 45/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0269 - accuracy: 0.9918 - precision: 0.9940 - recall: 0.9896 - val_loss: 1.4978 - val_accuracy: 0.7980 - val_precision: 0.7182 - val_recall: 0.9810\n",
      "Epoch 46/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0147 - accuracy: 0.9948 - precision: 0.9954 - recall: 0.9942 - val_loss: 0.9577 - val_accuracy: 0.8500 - val_precision: 0.7971 - val_recall: 0.9390\n",
      "Epoch 47/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0240 - accuracy: 0.9922 - precision: 0.9942 - recall: 0.9902 - val_loss: 1.0964 - val_accuracy: 0.8415 - val_precision: 0.7806 - val_recall: 0.9500\n",
      "Epoch 48/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0347 - accuracy: 0.9883 - precision: 0.9904 - recall: 0.9862 - val_loss: 1.2186 - val_accuracy: 0.8255 - val_precision: 0.7619 - val_recall: 0.9470\n",
      "Epoch 49/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0181 - accuracy: 0.9935 - precision: 0.9948 - recall: 0.9922 - val_loss: 1.3052 - val_accuracy: 0.8260 - val_precision: 0.7539 - val_recall: 0.9680\n",
      "Epoch 50/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0177 - accuracy: 0.9947 - precision: 0.9960 - recall: 0.9934 - val_loss: 1.2035 - val_accuracy: 0.8215 - val_precision: 0.7542 - val_recall: 0.9540\n",
      "Epoch 51/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0108 - accuracy: 0.9969 - precision: 0.9974 - recall: 0.9964 - val_loss: 1.1657 - val_accuracy: 0.8470 - val_precision: 0.7966 - val_recall: 0.9320\n",
      "Epoch 52/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0162 - accuracy: 0.9947 - precision: 0.9964 - recall: 0.9930 - val_loss: 1.1347 - val_accuracy: 0.8420 - val_precision: 0.7771 - val_recall: 0.9590\n",
      "Epoch 53/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0288 - accuracy: 0.9901 - precision: 0.9912 - recall: 0.9890 - val_loss: 1.5054 - val_accuracy: 0.8240 - val_precision: 0.7504 - val_recall: 0.9710\n",
      "Epoch 54/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0117 - accuracy: 0.9958 - precision: 0.9964 - recall: 0.9952 - val_loss: 1.3700 - val_accuracy: 0.8280 - val_precision: 0.7555 - val_recall: 0.9700\n",
      "Epoch 55/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0084 - accuracy: 0.9972 - precision: 0.9980 - recall: 0.9964 - val_loss: 1.3169 - val_accuracy: 0.8250 - val_precision: 0.7515 - val_recall: 0.9710\n",
      "Epoch 56/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0354 - accuracy: 0.9878 - precision: 0.9890 - recall: 0.9866 - val_loss: 0.8715 - val_accuracy: 0.8400 - val_precision: 0.8944 - val_recall: 0.7710\n",
      "Epoch 57/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0174 - accuracy: 0.9949 - precision: 0.9968 - recall: 0.9930 - val_loss: 1.5465 - val_accuracy: 0.8120 - val_precision: 0.7339 - val_recall: 0.9790\n",
      "Epoch 58/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0071 - accuracy: 0.9979 - precision: 0.9984 - recall: 0.9974 - val_loss: 1.0986 - val_accuracy: 0.8460 - val_precision: 0.7845 - val_recall: 0.9540\n",
      "Epoch 59/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0089 - accuracy: 0.9968 - precision: 0.9982 - recall: 0.9954 - val_loss: 1.3626 - val_accuracy: 0.8305 - val_precision: 0.7621 - val_recall: 0.9610\n",
      "Epoch 60/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0072 - accuracy: 0.9978 - precision: 0.9982 - recall: 0.9974 - val_loss: 1.3740 - val_accuracy: 0.8280 - val_precision: 0.7575 - val_recall: 0.9650\n",
      "Epoch 61/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0088 - accuracy: 0.9977 - precision: 0.9986 - recall: 0.9968 - val_loss: 1.3243 - val_accuracy: 0.8400 - val_precision: 0.7755 - val_recall: 0.9570\n",
      "Epoch 62/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0538 - accuracy: 0.9814 - precision: 0.9839 - recall: 0.9788 - val_loss: 1.1681 - val_accuracy: 0.8510 - val_precision: 0.7945 - val_recall: 0.9470\n",
      "Epoch 63/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0112 - accuracy: 0.9958 - precision: 0.9962 - recall: 0.9954 - val_loss: 1.3482 - val_accuracy: 0.8310 - val_precision: 0.7615 - val_recall: 0.9640\n",
      "Epoch 64/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0280 - accuracy: 0.9889 - precision: 0.9902 - recall: 0.9876 - val_loss: 1.4662 - val_accuracy: 0.8120 - val_precision: 0.7342 - val_recall: 0.9780\n",
      "Epoch 65/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0108 - accuracy: 0.9965 - precision: 0.9978 - recall: 0.9952 - val_loss: 1.8680 - val_accuracy: 0.7970 - val_precision: 0.7171 - val_recall: 0.9810\n",
      "Epoch 66/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0062 - accuracy: 0.9979 - precision: 0.9984 - recall: 0.9974 - val_loss: 1.0543 - val_accuracy: 0.8395 - val_precision: 0.7991 - val_recall: 0.9070\n",
      "Epoch 67/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0127 - accuracy: 0.9962 - precision: 0.9978 - recall: 0.9946 - val_loss: 1.6889 - val_accuracy: 0.8190 - val_precision: 0.7413 - val_recall: 0.9800\n",
      "Epoch 68/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0054 - accuracy: 0.9986 - precision: 0.9994 - recall: 0.9978 - val_loss: 1.2843 - val_accuracy: 0.8480 - val_precision: 0.7816 - val_recall: 0.9660\n",
      "Epoch 69/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0048 - accuracy: 0.9989 - precision: 0.9990 - recall: 0.9988 - val_loss: 1.0224 - val_accuracy: 0.8535 - val_precision: 0.8115 - val_recall: 0.9210\n",
      "Epoch 70/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0243 - accuracy: 0.9913 - precision: 0.9932 - recall: 0.9894 - val_loss: 1.1960 - val_accuracy: 0.8465 - val_precision: 0.7857 - val_recall: 0.9530\n",
      "Epoch 71/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0086 - accuracy: 0.9972 - precision: 0.9974 - recall: 0.9970 - val_loss: 1.6420 - val_accuracy: 0.8115 - val_precision: 0.7319 - val_recall: 0.9830\n",
      "Epoch 72/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0079 - accuracy: 0.9980 - precision: 0.9986 - recall: 0.9974 - val_loss: 1.6081 - val_accuracy: 0.8150 - val_precision: 0.7376 - val_recall: 0.9780\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0154 - accuracy: 0.9953 - precision: 0.9958 - recall: 0.9948 - val_loss: 1.1977 - val_accuracy: 0.8365 - val_precision: 0.7924 - val_recall: 0.9120\n",
      "Epoch 74/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0549 - accuracy: 0.9845 - precision: 0.9869 - recall: 0.9820 - val_loss: 1.5090 - val_accuracy: 0.8190 - val_precision: 0.7409 - val_recall: 0.9810\n",
      "Epoch 75/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0126 - accuracy: 0.9964 - precision: 0.9970 - recall: 0.9958 - val_loss: 1.1917 - val_accuracy: 0.8455 - val_precision: 0.7901 - val_recall: 0.9410\n",
      "Epoch 76/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0037 - accuracy: 0.9990 - precision: 0.9996 - recall: 0.9984 - val_loss: 1.3827 - val_accuracy: 0.8365 - val_precision: 0.7652 - val_recall: 0.9710\n",
      "Epoch 77/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0038 - accuracy: 0.9987 - precision: 0.9994 - recall: 0.9980 - val_loss: 1.5833 - val_accuracy: 0.8215 - val_precision: 0.7456 - val_recall: 0.9760\n",
      "Epoch 78/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0057 - accuracy: 0.9982 - precision: 0.9986 - recall: 0.9978 - val_loss: 1.7630 - val_accuracy: 0.8140 - val_precision: 0.7350 - val_recall: 0.9820\n",
      "Epoch 79/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0159 - accuracy: 0.9953 - precision: 0.9958 - recall: 0.9948 - val_loss: 1.5644 - val_accuracy: 0.8270 - val_precision: 0.7515 - val_recall: 0.9770\n",
      "Epoch 80/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0159 - accuracy: 0.9944 - precision: 0.9948 - recall: 0.9940 - val_loss: 1.8234 - val_accuracy: 0.8230 - val_precision: 0.7466 - val_recall: 0.9780\n",
      "Epoch 81/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0084 - accuracy: 0.9973 - precision: 0.9980 - recall: 0.9966 - val_loss: 1.7183 - val_accuracy: 0.8230 - val_precision: 0.7496 - val_recall: 0.9700\n",
      "Epoch 82/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0070 - accuracy: 0.9976 - precision: 0.9980 - recall: 0.9972 - val_loss: 2.1123 - val_accuracy: 0.7910 - val_precision: 0.7097 - val_recall: 0.9850\n",
      "Epoch 83/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0120 - accuracy: 0.9963 - precision: 0.9970 - recall: 0.9956 - val_loss: 1.1445 - val_accuracy: 0.8595 - val_precision: 0.8113 - val_recall: 0.9370\n",
      "Epoch 84/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0231 - accuracy: 0.9912 - precision: 0.9940 - recall: 0.9884 - val_loss: 1.5660 - val_accuracy: 0.8290 - val_precision: 0.7578 - val_recall: 0.9670\n",
      "Epoch 85/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0028 - accuracy: 0.9991 - precision: 0.9994 - recall: 0.9988 - val_loss: 1.2768 - val_accuracy: 0.8500 - val_precision: 0.7941 - val_recall: 0.9450\n",
      "Epoch 86/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0077 - accuracy: 0.9976 - precision: 0.9982 - recall: 0.9970 - val_loss: 1.4846 - val_accuracy: 0.8390 - val_precision: 0.7669 - val_recall: 0.9740\n",
      "Epoch 87/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0153 - accuracy: 0.9952 - precision: 0.9960 - recall: 0.9944 - val_loss: 0.9968 - val_accuracy: 0.8610 - val_precision: 0.8532 - val_recall: 0.8720\n",
      "Epoch 88/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0199 - accuracy: 0.9935 - precision: 0.9944 - recall: 0.9926 - val_loss: 2.0304 - val_accuracy: 0.7940 - val_precision: 0.7137 - val_recall: 0.9820\n",
      "Epoch 89/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0026 - accuracy: 0.9993 - precision: 0.9992 - recall: 0.9994 - val_loss: 1.8701 - val_accuracy: 0.8150 - val_precision: 0.7368 - val_recall: 0.9800\n",
      "Epoch 90/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 5.3803e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.1226 - val_accuracy: 0.8035 - val_precision: 0.7230 - val_recall: 0.9840\n",
      "Epoch 91/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 6.7770e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.2319 - val_accuracy: 0.7925 - val_precision: 0.7106 - val_recall: 0.9870\n",
      "Epoch 92/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0470 - accuracy: 0.9860 - precision: 0.9872 - recall: 0.9848 - val_loss: 1.5377 - val_accuracy: 0.8175 - val_precision: 0.7471 - val_recall: 0.9600\n",
      "Epoch 93/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0053 - accuracy: 0.9980 - precision: 0.9986 - recall: 0.9974 - val_loss: 1.4888 - val_accuracy: 0.8360 - val_precision: 0.7662 - val_recall: 0.9670\n",
      "Epoch 94/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 8.8265e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7551 - val_accuracy: 0.8260 - val_precision: 0.7512 - val_recall: 0.9750\n",
      "Epoch 95/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0080 - accuracy: 0.9973 - precision: 0.9976 - recall: 0.9970 - val_loss: 1.3987 - val_accuracy: 0.8240 - val_precision: 0.7634 - val_recall: 0.9390\n",
      "Epoch 96/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0181 - accuracy: 0.9942 - precision: 0.9950 - recall: 0.9934 - val_loss: 1.9627 - val_accuracy: 0.8065 - val_precision: 0.7272 - val_recall: 0.9810\n",
      "Epoch 97/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0038 - accuracy: 0.9985 - precision: 0.9986 - recall: 0.9984 - val_loss: 1.7085 - val_accuracy: 0.8255 - val_precision: 0.7517 - val_recall: 0.9720\n",
      "Epoch 98/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0011 - accuracy: 0.9999 - precision: 1.0000 - recall: 0.9998 - val_loss: 2.1155 - val_accuracy: 0.8005 - val_precision: 0.7195 - val_recall: 0.9850\n",
      "Epoch 99/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0134 - accuracy: 0.9957 - precision: 0.9964 - recall: 0.9950 - val_loss: 1.4085 - val_accuracy: 0.8305 - val_precision: 0.7625 - val_recall: 0.9600\n",
      "Epoch 100/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0202 - accuracy: 0.9935 - precision: 0.9948 - recall: 0.9922 - val_loss: 1.4233 - val_accuracy: 0.8445 - val_precision: 0.7831 - val_recall: 0.9530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21444bb5100>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "model6 = MyModel_Aug()\n",
    "model6.compile(optimizer = 'adam',\n",
    "               loss = 'binary_crossentropy',\n",
    "               # Precision and Recall are useful to detect the problem\n",
    "               # caused by the model which ignores imbalanced data.\n",
    "               metrics = ['accuracy',\n",
    "                          tf.keras.metrics.Precision(name = 'precision'),\n",
    "                          tf.keras.metrics.Recall(name = 'recall')])\n",
    "model6.fit(train_ds, validation_data = test_ds, epochs = EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f877ada",
   "metadata": {},
   "source": [
    "It is not appropriate to apply SMOTE to video data.<br>\n",
    "It is better to apply SMOTE after we extract features from video data, which will yield better performance models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
